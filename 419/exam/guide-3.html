<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title> CS 419 Exam 3 Study Guide </title>

<link href="../../css/layout.css" rel="stylesheet" type="text/css" />
<link href="../../css/main.css" rel="stylesheet" type="text/css" />
<link href="../../css/print.css" rel="stylesheet" type="text/css" media="print" />
<link href="../../css/main-print.css" rel="stylesheet" type="text/css" media="print" />
<style type="text/css">
.rqbox {
	text-align: center;
	margin-left: auto;
	margin-right: auto;
        position: relative;
	width: 15em;
        background-color: #FDF5B6;
        border-style: double; border-width: 3px;
        padding: 0.5em 0.5em 0.5em 0.5em;
}
</style>
</head>

<body id="s_ru419">
<div id="wrapper">
<!-- _______________________________________ BANNER _______________________________________ -->
<div id="banner">
  <div id="logo">
  <img src="../../css/images/pk-org-pencil.png" alt="pk.org" name="logo" width="122" height="45"/>
  </div>
  <div id="title"> Computer Security </div>
  <div id="search">
  <form method="get" action="http://www.google.com/search">
	<div style="border:none ;padding:2px;width:25em;">
	<input type="text" name="q" size="25" maxlength="255" value="" />
	<input type="submit" value="Search" />
	<input type="hidden"  name="sitesearch" value="www.pk.org" checked />
	</div>
  </form>
  </div>
  <ul>
    <li class="separator"><a href="../../about/index.html">About</a></li>
    <li class="separator"><a href="../../about/contact.html">Contact</a></li>
    <li><a href="../../sitemap.html">Site map</a></li>
  </ul>
</div>

<!-- _______________________________________ MAIN NAV _______________________________________ -->
<div id="navbar">
	<ul>
	<li class="homelink"><a href="../../index.html">Home</a></li>
<!--
	<li class="aboutlink"><a href="../../about/index.html">About</a></li>
-->
	<li class="ru"><a href="../../rutgers/index.html">Rutgers</a></li>
	<li class="ru352"><a href="../../352/index.html">Internet Technology [352]</a></li>
	<li class="ru416"><a href="../../416/index.html">Operating Systems [416]</a></li>
	<li class="ru417"><a href="../../417/index.html">Distributed Systems [417]</a></li>
	<li class="ru419"><a href="../../419/index.html">Computer Security [419]</a></li>
	<li class="cslink"><a href="../../cs/index.html">Computing</a></li>
	<li class="photolink"><a href="../../photo/index.html">Photography</a></li>
<!--
	<li class="funlink"><a href="#">Coming</a></li>
	<li class="funlink"><a href="#">Soon</a></li>
-->
	</ul>
</div>

<div id="subnav">
<P>
You are in: 
</p>
<ul>
	<li class="first"> <a href="index.html"> Home </a>  </li>
 	<li> <a href="../../index.html"> Rutgers </a>  </li>
 	<li> <a href="../index.html"> CS 419 </a>  </li>
 	<li> <a href="../exam/index.html"> Exam info </a>  </li>
 	<li> <a href="../exam/guide-3.html"> Exam 3 study guide </a>  </li>
</ul>
</div>
<div id="content-wrapper">
<div id="main">
<div id="headline">
<h1> Exam 3 study guide </h1>
<h2> The one-hour study guide for exam 3 </h2>
<p class="author"> Paul Krzyzanowski </p>
<p class="date"> Latest update: Wed May 20 13:43:00 EDT 2020
 </p>
</div>

<p class="first">

Disclaimer: 
This study guide attempts to touch upon the most
important topics that may be covered on the exam but does not claim to
necessarily cover everything that one needs to know for the exam. Finally,
don't take the <i>one hour</i> time window in the title literally.</p>

<h1 id="bitcoinblockchain">Bitcoin &amp; Blockchain</h1>

<p>Bitcoin was introduced anonymously in 2009 by a person or group named Satoshi Nakamoto and is considered to be the first blockchain-based cryptocurrency. Bitcoin was designed as an open, distributed, public system: there is no authoritative entity and anyone can participate in operating the servers.</p>

<p>Traditional payment systems rely on banks to serve as a trusted third party. If Alice pays $500 to Charles, the bank, acting as a trusted third party, deducts $500 from Alice&#8217;s account and adds $500 to Charles&#8217; account. Beyond auditing, there is no need to maintain a log of all transactions; we simply care about account sums. With a centralized system, all trust resides in this trusted third party. The system fails if the bank disappears, the banker makes a mistake, or if the banker is corrupt.</p>

<p>With Bitcoin, the goal was to create a completely decentralized, distributed system that allows people to manage transactions while preventing opportunities for fraud. </p>

<h2 id="theledgerandthebitcoinnetwork">The ledger and the Bitcoin network</h2>

<p>Bitcoin maintains a complete list of every single transaction since its creation in January 2009. This list of transactions is called the <strong>ledger</strong> and is stored in a structure called a <strong>blockchain</strong>. Complete copies of the ledger are replicated at Bitcoin nodes around the world. There is no concept of a master node or master copies of the ledger. All of these systems run the same software. New systems get the names of some well-known nodes when they download the software and DNS query on these nodes returns their IP addresses. After connecting to one or more nodes, a Bitcoin node will ask each for a list of known Bitcoin nodes. This creates a <strong>peer discovery</strong> process that allows a node to get a complete list of other nodes in the network.</p>

<h2 id="useridentitiesandaddresses">User identities and addresses</h2>

<p>We know how to create unforgeable messages: just <em>sign</em> them. If Alice wants to transfer $500 to Charles, she can create a transaction record that describes this transfer and sign it with her private key (e.g., use a digital signature algorithm or create a hash of the transaction and encrypt it with her private key). Bitcoin uses public-private key pairs and digital signatures to sign transactions. </p>

<p>Bitcoin transactions &#8212; the movement of bitcoins from one account to another &#8212; are associated with public these keys and not users.
Users are <strong>anonymous</strong>. Your identity is your public key and you can use this identity by proving they have the corresponding private key.</p>

<p>There is never any association of your public key with your name. In fact, nothing stops you from creating multiple keys and having identities. The system does not care, or know, what your physical identity is or how many addresses you assigned to yourself. All that matters is that only you have the corresponding private keys to the public keys identified in your transactions so you are the only one who could have created valid signatures for your transactions. </p>

<p>If you can create transactions on behalf of a specific public key, it means that you own the corresponding private key. If you lose that private key, then you can no longer create transactions and hence cannot access your Bitcoin funds. There is nobody to call to recover a lost key since you are solely responsible for storing it!</p>

<p>In its initial deployment, your public key was your Bitcoin identity. If someone wanted to transfer money to you, they would create a transaction where your public key is identified as the recipient of the bitcoin. Bitcoin now identifies recipients by their <strong>Bitcoin address</strong>. Your Bitcoin address is essentially a hash of your public key (and you will have several addresses if you have several keys). The details of creating an address are a bit cumbersome:</p>

<ol>
<li><p>Generate an ECDSA (Elliptic Curve Digital Signature Algorithm) public, private key pair. This serves as your identity and signing key.</p></li>
<li><p>Create a <a href="https://en.wikipedia.org/wiki/SHA-2">SHA&#8211;256</a> hash of the public key</p></li>
<li><p>Perform a <a href="https://en.wikipedia.org/wiki/RIPEMD">RIPEMD&#8211;160</a> hash on that</p></li>
<li><p>Add a version byte in front of the result</p></li>
<li><p>Perform a SHA&#8211;256 hash on the result &#8230; and another SHA&#8211;256 hash on that result</p></li>
<li><p>The four bytes of the result are treated as the address checksum. Add these four bytes to the end of the RIPEMD&#8211;160 hash from [4]</p></li>
<li><p>Convert the bytes to a base&#8211;58 string using <a href="https://en.bitcoin.it/wiki/Base58Check_encoding">Base58Check</a> encoding to create a 20-byte printable string. Base58Check encoding adds a checksum to be able to validate that the value is not mistyped. This string is your <em>bitcoin address</em>.</p></li>
</ol>

<p>When all is said and done, the address is essentially just a hash of your public key. Since a hash is a one-way function, someone can create (or verify) your address if they are presented with your public key. However, they cannot derive your public key if they have your address.</p>

<p>Bitcoin uses addresses <em>only</em> as destinations; an address can only receive funds. If Bob wants to send bitcoin to Alice, he will identify Alice as the output &#8211; the target of the money &#8211; by using her address. At some point in the future, Alice can use that money by creating a transaction whose source (input) refers to the transaction where she received the bitcoin. Any bitcoin node can validate this transaction:</p>

<ul>
<li><p>Alice&#8217;s transaction will identify where the money comes from (inputs). Each input contains contains a reference to a past transaction, her public key, and her signature.</p></li>
<li><p>A node can validate the signature by using Alice&#8217;s public key, which is also a field of the input. This proves that someone who owns the private key (Alice) that corresponds to that public key created the transaction.</p></li>
<li><p>That transaction input contains a reference to an older transaction where the output &#8211; Alice&#8217;s address &#8211; is identified as the output of the bitcoin. Given the address, we cannot derive the public key but now we have both.</p></li>
<li><p>A bitcoin node can hash Alice&#8217;s public key (from the input) to create the address and see that it is the same as in the referenced old transaction (the output). That way, it validates that the older transaction indeed gives money to Alice.</p></li>
</ul>

<h2 id="usertransactionsmovingcoins">User transactions (moving coins)</h2>

<p>A transaction contains <strong>inputs</strong> and <strong>outputs</strong>. Inputs identify where the bitcoin comes from and outputs identify where to whom it is being transferred.
If Alice wants to send bitcoin to Bob, she creates a message that is a bitcoin transaction and sends it to one or more bitcoin nodes. When a node receives a message, it will forward the transaction to its peers (other nodes it knows about). Typically, within approximately five seconds, every bitcoin node on the network will have a copy of the transaction and can process it.</p>

<p>The bitcoin network is not a database. It is build around a ledger, the list of all transactions. There are no user accounts that can be queried. In her transaction, Alice needs to provide one or more links to previous transactions that will add up to at least the required amount of bitcoin that she&#8217;s sending. These links to earlier transactions are called <strong>inputs</strong>. Each input is an ID of an earlier transaction. Inputs are outputs of previous transactions.</p>

<p>When a bitcoin node receives a transaction, it performs several checks:</p>

<ol>
<li><p>The signature of each input is validated by checking it against the public key in the transaction. This ensures that it was created by someone who has the private key that corresponds to the public key.</p></li>
<li><p>It hashes the public key in the transaction to create the <em>address</em>, which will be matched against the output addresses in the inputs.</p></li>
<li><p>The transactions listed in the inputs are validated to make sure that those transactions have not been used by any other transaction. This ensures there will be no <strong>double spending</strong>. </p></li>
<li><p>Finally, it makes sure that there is a sufficient quantity of bitcoin output by those input transactions.</p></li>
</ol>

<p>A bitcoin transaction contains:</p>
<dl>
<dt>One or more inputs:</dt>
<dd>Each input identifies transactions where coins come from. These are references to past transactions. Each input also contains a signature and a public key that corresponds to the private key that was used to create the signature. A user may have multiple identities (keys) and reference past transactions that were directed to different addresses that belong to the user.</dd>

<dt>Output:</dt>
<dd>Destination address &amp; amount &#8211; who the money goes to. This is simply the recipient&#8217;s bitcoin address.</dd>
</dl>


<p>Change:
: The transaction owner’s address &amp; bitcoin amount. Every input must be completely spent Any excess is generated as another output to the owner of the transaction.</p>

<p>Transaction fee (anywhere from 10¢ to a few $ per transaction).
There is a limited amount of space (about 1 MB) in a block. A transaction is about 250 bytes. To get your transaction processed quickly, you need to outbid others. </p>

<h2 id="blocksandtheblockchain">Blocks and the blockchain</h2>

<p>Transactions are sent to all the participating servers. Each system keeps a <strong>complete copy</strong> of the entire ledger, which records all transactions from the very first one. Currently the bitcoin ledger is about <a href="https://www.blockchain.com/en/charts/blocks-size">250 GB</a>.</p>

<p>Transactions are grouped into a <strong>block</strong>. A block is just a partial list of transactions. When a server is ready to do so, it can add the block to the ledger, forming a linked list of blocks that comprise the <strong>blockchain</strong>. In Bitcoin, a block contains ten minutes worth of transactions, all of which are considered to be concurrent. </p>

<p>Every ten minutes, a new block of transactions is added to the blockchain. A block is approximately a megabyte in size and holds around 4,000 transactions. To make it easy to locate a specific transaction within a block, the blocks are stored in a <strong>Merkle tree</strong>. This is a binary tree of hash pointers and makes it easy not just to locate a desired transaction but to validate that it has not been tampered by validating the chain of hashes along the path.</p>

<h2 id="securingtheblock">Securing the Block</h2>

<p>A critically important part of the Bitcoin blockchain is to make sure that blocks in the blockchain have not been modified. We explored the basic concept of a blockchain earlier. Each block contains a <strong>hash pointer</strong> to the previous block in the chain. A hash pointer not only points to the previous block but also contains a SHA&#8211;256<a href="#fn:1" id="fnref:1" title="see footnote" class="footnote">[1]</a> hash of that block. This creates a <strong>tamper-proof</strong> structure. If the contents of any block are modified (accidentally or maliciously), the hash pointer that points to that block will no longer be valid (the hashes won&#8217;t match).</p>

<p>To make a change to a block, an attacker will need to modify all the hash pointers from the most recent block back to the block that was changed. One way to prevent such a modification could have been to use signed hash pointers to ensure an attacker cannot change their values. However, that would require someone to be in charge of signing these pointers and there is no central authority in Bitcoin; anyone can participate in building the blockchain. We need a different way to protect blocks from modification.</p>

<h3 id="proofofwork">Proof of Work</h3>

<p>Bitcoin makes the addition of a new block &#8211; or modification of a block in a blockchain &#8211; difficult by creating a <strong>puzzle</strong> that needs to be solved before the block can be added to the blockchain. By having a node solve a sufficiently difficult puzzle, there will be only a tiny chance that two or more nodes will propose adding a block to the chain at the same time.</p>

<p>This puzzle is called the <strong>Proof of Work</strong> and is an idea that has been adapted from an earlier system called <a href="https://en.wikipedia.org/wiki/Hashcash">hashcash</a>. Proof of Work requires computing a hash of three components, <em>hash(B, A, W)</em> where:</p>

<ul>
<li><em>B</em> = block of transactions (which includes the hash pointer to the previous block)</li>
<li><em>A</em> = address (i.e., hash of the public key) of the owner of the server doing the computation</li>
<li><em>W</em> = the Proof of Work number</li>
</ul>

<p>When servers are ready to commit a block of transactions onto the chain, they each compute this hash, trying various values of <em>W</em> until the hash result has a specific pre-defined property. The property they are searching for is a hash value that is less than some given number. Currently, it&#8217;s a value that requires the leading 74 bits of the 256-bit hash to all be 0s). The property changes over time to ensure that the puzzle never gets too easy regardless of how many nodes are in the network or how fast processors get.</p>

<p>Recall that one property of a cryptographic hash function is the inability to deduce any of the input by looking at the output. Hence, we have no idea what values of <em>W</em> will yield a hash with the desired properties. Servers have to try trillions of values with the hope that they will get lucky and find a value that yields the desired hash. This process of searching for <em>W</em> is called <strong>mining</strong>.</p>

<p>When a server finds a value of <em>W</em> that yields the desired hash, it advertises that value to the entire set of bitcoin servers. Upon receiving this message, it is trivial for a server to validate the proof of work by simply computing <em>hash(B, A, W)</em> with the <em>W</em> sent in the message and checking the resultant value. The servers then add the block, which contains the Proof of Work number and the winner&#8217;s address, onto the blockchain.</p>

<p>Bitcoin&#8217;s mining difficulty is adjusted every 2,016 blocks, which corresponds to approximately 14 days, to keep the average rate at which blocks are added to the blockchain at 10 minutes. This allows the network to handle changes in the number of miners participating in computing the proof work.</p>

<h3 id="doublespendingandmodifyingpasttransactions">Double Spending and modifying past transactions</h3>

<p>A major concern with decentralized cryptocurrency systems is <strong>double spending</strong>. Double spending refers to sending the same funds (or tokens) to multiple parties: Alice sends $500 to Charles and $500 to David but only has $500 in her account. Bitcoin deals with this by having every server maintain the complete ledger, so Alice&#8217;s entire list of transactions can be validated before a new one is accepted.</p>

<p>Alice may decide to go back to an older transaction and modify it. For example, she might change change the transaction that sent bitcoin to Charles into one that sends money to David &#8211; or simply delete the fact that she paid Charles the full amount. </p>

<p>To do this, she would need to compute a new proof of work value for that block so the block hash will be valid. Since Bitcoin uses hash pointers, each block contains a hash pointer to the previous (earlier) block. Alice would thus need to compute new proof of work values for all newer blocks in the chain so that her modified version of the entire blockchain is valid. She ends up making a <strong>competing blockchain</strong>.</p>

<p>Recomputing the proof of work numbers is a computationally intensive process. Because of the requirement to generate the Proof of Work for each block, a malicious participant will not be able to catch up with the cumulative work of all the other participants. Because of errors or the rare instances where multiple nodes compute the proof of work concurrently, even honest participants may, on occasion, end up building a competing blockchain. Bitcoin&#8217;s policy is that <strong>the longest chain in the network is the correct one</strong>. The length of the chain is the chain&#8217;s <strong>score</strong> and the highest-scoring chain will be considered the correct one by the servers. A participant is obligated to update its chain with a higher-scoring one if it gets notice of a higher-scoring chain from another system. If it doesn&#8217;t update and insists on propagating its chain as the official one, its chain will simply be ignored by others.</p>

<h3 id="attack">51% Attack</h3>

<p>Let us go back to the example of Alice maliciously modifying a past transaction. In addition to the work of modifying the existing blockchain, Alice will also need to process new transactions that are steadily arriving, and making the blockchain get longer as new blocks get added to it. She needs to change the existing blockchain and also compute proof of work values for new blocks faster than everyone else in the network so that she would have the longest valid chain and hence a high score. </p>

<p>If she can do this then her chain becomes the official version of the blockchain and everyone updates their copy.
This is called a <strong>51% attack</strong>. To even have a chance of succeeding, Alice would need more computing power than the reset of the systems in the Bitcoin network combined. Back in 2017, The <a href="https://www.economist.com/the-economist-explains/2015/01/20/how-bitcoin-mining-works">Economist</a> estimated that &#8220;bitcoin miners now have 13,000 times more combined number-crunching power than the world’s 500 biggest supercomputers,&#8221; so it is not feasible for even a nation-state attacker to harness sufficient power to carry out this attack on a popular cryptocurrency network such as Bitcoin. Blockchain works only because of the assumption that the majority of participants are honest &#8230; or at least not conspiring together to modify the same transactions.</p>

<p>Even if someone tried to do this attack, they&#8217;d likely only be able to modify transactions in very recent history &#8211; in the past few blocks of the blockchain. This is why For this reason, transactions further back in the blockchain are considered to be more secure.</p>

<h2 id="committingtransactions">Committing Transactions</h2>

<p>Because of the chain structure, it requires more work to modify older transactions (more blocks = more proof of work computations). Modifying only the most recent block is not hugely challenging. Hence, the further back a transaction is in the blockchain, the less likely it is that anyone can amass the computing power to change it and create a competing blockchain. </p>

<p>A transaction is considered <strong>confirmed</strong> after some number, <em>N</em>, additional blocks are added to the chain.
The value of <em>N</em> is up to the party receiving the transaction - a level of comfort. The higher the number, the deeper the transaction is in the blockchain and the harder it is to alter. Bitcoin recommends <em>N</em>=1 for low-value transactions (payments under $1,000; this enables them to be confirmed quickly), <em>N</em>=3 for deposits and mid-value transactions, and <em>N</em>=6 for large payments (e.g., $10k&#8230;$1M). Even larger values of <em>N</em> could be used for extremely large payments.</p>

<h2 id="rewards">Rewards</h2>

<p>Why would servers spend a huge amount of computation, which translates to huge investments in computing power and electricity, just to find a value that produces a hash with a certain property? To provide an incentive, the system rewards the <em>first</em> server (the <strong>miner</strong>) that advertises a successful Proof of Work number by depositing a certain number of Bitcoins into their account. To avoid rewarding false blockchains as well as to encourage continued mining efforts, the miner is rewarded only after 99 additional blocks have been added to the ledger.</p>

<p>The reward for computing a proof of work has been designed to decrease over time:</p>

<ul>
<li>50 bitcoins for the first 4 years since 2008</li>
<li>25 bitcoins from 2012&#8211;2015</li>
<li>12.5 bitcoins from block #420,000 July 9, 2016 – 2019</li>
<li>6.25 bitcoins at block #630,000 – around May 24, 2020</li>
</ul>

<p>Eventually, the reward will reach zero and there will be a maximum of around 21 million bitcoins in circulation. However, recall that each transaction has a fee associated with it. Whoever solves the puzzle first and gets a confirmed block into the blockchain will also reap the sum of all the transaction fees in that block.</p>

<h2 id="centralization">Centralization</h2>

<p>Bitcoin has been designed to operate as a large-scale, global, fully decentralized network. Anybody can download the software and operate a bitcoin node. All you need is sufficient storage to store the blockchain. There are currently over 9,000 reachable full nodes spread across 99 countries. It is <a href="https://bitcoinist.com/bitcoin-network-surpasses-100000-nodes-new-data-shows/">estimated</a> that there are over 100,000 total nodes, including those that are be running old versions of software or are not always reachable. In this sense, Bitcoin is truly decentralized. Note that there are <a href="https://thenextweb.com/hardfork/2019/03/01/bitcoin-blockchain-nodes-network/">different types of nodes</a>. The nodes we discussed serve as <strong>full nodes</strong>. They maintain an entire copy of the blockchain and accept transactions. Light nodes are similar but store only a part of the blockchain, talking to a full node parent if they need to access other blocks.</p>

<p>Not everyone who operates a bitcoin node does mining (proof of work computation). Mining is incredibly time energy intensive. To make money on mining, one needs to buy dedicated ASIC mining hardware that is highly optimized to compute SHA&#8211;256 hashes. Conventional computers will cost more in energy than they will earn in bitcoin rewards. Because of this, mining tends to be concentrated among a far smaller number of players. It is not as decentralized as much as one would like.</p>

<p>Bitcoin software is open source but there is only a small set of trusted developers. The software effort is inspectable but not really decentralized. Bugs have been fixed but many nodes still run old and <a href="https://thenextweb.com/hardfork/2019/05/06/bitcoin-100000-nodes-vulnerable-cryptocurrency/">buggy</a> versions. Bitcoin transactions cannot be undone even if they were created by buggy nodes or via compromised keys. </p>

<!--
https://cointelegraph.com/news/crypto-under-attack-the-five-worst-hacks-that-shook-the-crypto-world
-->

<div class="footnotes">
<hr />
<ol>

<li id="fn:1">
<p>SHA&#8211;256 is the SHA&#8211;2 family of hash functions that produces a 256-bit output. The SHA&#8211;2 family also includes HA&#8211;224, SHA&#8211;256, SHA&#8211;384, and SHA&#8211;512. <a href="#fnref:1" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

</ol>
</div>


<h1 id="networksecurity">Network Security</h1>

<p>The Internet was designed to support the interconnection of multiple networks, each of
which may use different underlying networking hardware and protocols. The <strong>Internet Protocol</strong>, IP, is a logical
network built on top of these physical networks. IP assumes that the underlying networks
do not provide reliable communication. It is up to higher layers of the IP software
stack (either TCP or thee application) to to detect lost packets. Individual networks under IP are
connected by routers, which are computing elements that are each connected to multiple networks.
They receive packets on one network and forward them onto another network to
get them to their destination. A packet from your computer will often flow through
multiple networks and multiple routers that you know nothing about on its way to its
destination. This poses security risks since you do not know of the trustworthiness
of the routers and networks.</p>

<p>Networking protocol stacks are usually described using the OSI layered model. For IP,
the layers are:</p>

<ol>
<li><p>Physical. Represents the actual hardware.</p></li>
<li><p>Data Link. The protocol for the local network, typically Ethernet (802.1) or Wi-Fi (802.11). Ethernet and Wi-Fi use the same addressing scheme and were designed to be bridged together to form a single local area network.</p></li>
<li><p>Network. The protocol for creating a single logical network and routing packets across physical networks. The Internet Protocol (IP) is responsible for this.</p></li>
<li><p>Transport. The transport layer is responsible for creating logical software endpoints (<strong>ports</strong>) so that one application can send a stream of data to another via an operating system&#8217;s <strong>sockets</strong> interface. TCP uses sequence numbers, acknowledgement numbers, and retransmission to provide applications with a reliable, connection-oriented, bidirectional communication channel. UDP does not provide reliability and simply sends a packet to a given destination host and port.</p></li>
</ol>

<p>Higher layers of the protocol stack are handled by applications and the libraries they use.</p>

<h2 id="datalinklayer">Data link layer</h2>

<p>In an Ethernet network, the data link layer is handled by Ethernet transceivers and Ethernet switches.
Security was not a consideration in the design of this layer and several fundamental attacks
exist at this layer. Wi-Fi also operates at the data link layer and added encryption on wireless data between the device and access point. Note that the encryption is not end-to-end, between hosts, but ends at the access point.</p>

<h3 id="switchcamtableoverflow">Switch CAM table overflow</h3>

<p><em>Sniff all data on the local area network (LAN).</em></p>

<p>Ethernet frames are delivered based on their 48-bit MAC<sup><a href="#fn:1" id="fnref:1" title="see footnote" class="footnote">[1]</a></sup> address. IP address are meaningless
to ethernet transceivers and to switches since IP is handled at higher levels of the network stack.
Ethernet was originally designed as a bus-based shared network; all devices on the LAN shared the same wire. Any system could see
all the traffic on the Ethernet. This resulted in increased congestion as more hosts
were added to the local network. </p>

<p>Ethernet switches alleviated this problem by using
a dedicated cable between each host and the switch. The switch routes an ethernet frame
<em>only</em> to the Ethernet port (the connector on the switch) that is connected to the system that contains the
desired destination address.</p>

<p>Unlike routers, switches are not programmed with routes. Instead, they learn which computers are on which switch ports
by looking at the source MAC addresses of incoming ethernet frames. An incoming
frame indicates that the system with that source address is connected to that
switch port.</p>

<p>To implement this, a switch contains a switch table (a MAC address table).
This table contains entries for known MAC addresses and their interface. The switch then uses <strong>forwarding and filtering</strong>:</p>

<blockquote>
<p>When a frame arrives for some destination address <em>D</em>,
the switch looks up <em>D</em> in the switch table to find the interface.
If <em>D</em> is in the table and on a different port than that of the incoming frame, the switch forwards the frame to that interface, queueing it if necessary.</p>

<p>If <em>D</em> is not found in the table, then the switch assumes it has not
yet learned what port that address is associated with, so it forwards the frame to <em>ALL</em> interfaces.</p>
</blockquote>

<p>This procedure makes the switch <strong>self-learning</strong>: the switch table is empty initially and gets populated as the switch inspects source addresses.</p>

<p>A switch has to support extremely rapid lookups in the switch table. For this
reason, the table is implemented using <strong>content addressable memory</strong> (<strong>CAM</strong>,
also known as associative memory). CAM is expensive and switch
tables are fixed-size and not huge. The switch will delete less-frequently
used entries if it needs to make room for new ones.</p>

<p>The <strong>CAM table overflow attack</strong> exploits
the limited size of this CAM-based switch table.
The attacker sends bogus Ethernet frames with random source MAC addresses.
Each newly-received address will displace an entry in the switch table,
eventually filling up the table.
With the CAM table full, legitimate traffic will be broadcast to all links
A host on any port can now see all traffic.
The CAM table overflow attack turns a switch into a hub.</p>

<p>Countermeasures for CAM table attacks require the use of
managed switches that support <strong>port security</strong>. These
switches allow you to limit the number of addresses the table will hold for each switch port.</p>

<h3 id="vlanhoppingswitchspoofing">VLAN hopping (switch spoofing)</h3>

<p><em>Sniff all data from connected virtual local area networks.</em></p>

<p>One use of local area networks is to
isolate broadcast traffic from other groups of systems.
Related users can all be placed on a single LAN.
However, users may be relocated within an office office and switches may be
used inefficiently.
<strong>Virtual Local Area Networks</strong> (VLANs)
create multiple logical LANs over a single physical switch infrastructure.
The network administrator can assign each port on a switch to a specific VLAN.
Each VLAN is a separate broadcast domain so that each VLAN acts
like a truly independent local area network. Users belonging to one VLAN will not see any traffic from the other; it has to be routed through an IP router.</p>

<p>Switches may be extended by cascading them with other switches:
an ethernet cable from one switch simply connects to another switch.
With VLANs, the connection between switches forms a <strong>VLAN trunk</strong>
and carries traffic from <em>all</em> VLANs to the other switch. To support this behavior, an
extended Ethernet frame format was created for theEthernet frames sent on this link since each frame now needs to identify
the VLAN from which it originated.</p>

<p>A <strong>VLAN hopping attack</strong> employs <strong>switch spoofing</strong>: an
attacker&#8217;s computer identifies itself as a switch with a trunk
connection. It then receives traffic on all VLANs.</p>

<p>Defending against this attack requires a managed
switch where an administrator can disable unused ports and
associate them with some unused VLAN.
Disable auto-trunking also needs to be disabled so that each port
cannot become a trunk. Instead, trunk ports need to be configured
explicitly.</p>

<h3 id="arpcachepoisoning">ARP cache poisoning</h3>

<p><em>Redirect IP packets by changing the IP address to MAC address mapping.</em></p>

<p>Recall that IP is a <em>logical</em> network that sits on top of
physical networks. If we are on an Ethernet network
and need to send an IP datagram, that IP datagram needs
to be encapsulated in an Ethernet frame. The
Ethernet frame needs to contain a destination
MAC address that corresponds to the destination
machine (or router, if the destination address is on a different LAN). For an operating system to send an IP packet, therefore, it needs to figure
out what MAC address corresponds to a given IP address.</p>

<p>There is no relationship between an IP and Ethernet
MAC address. To find the MAC address when given an IP
address, a system uses the <strong>Address Resolution Protocol</strong>,
<strong>ARP</strong>. The sending computer creates an Ethernet frame
that contains an ARP message with the IP address it
wants to query. This ARP message is then <strong>broadcast</strong>: all network adapters on the LAN receive the message.
If some system receives this message and sees that
its IP address matches the address in the query, it sends back an <strong>ARP response</strong>. The response identifies the MAC
address of the system that owns that IP address.</p>

<p>To avoid the overhead of doing this query each time
the system needs to use the IP address, the operating
system maintains an <strong>ARP cache</strong> that stores recently
used addresses. Moreover,
hosts cache <em>any</em> ARP replies they see, even if they
did not originate them. This is done on the assumption
that many systems use the same set of IP addresses and
the overhead of making an ARP query is substantial.
Along the same lines, a computer can send an ARP response even if nobody sent a request. This is called a <strong>gratuitious ARP</strong> and is often sent by computers when they start up as a way to give other systems on the LAN the IP:MAC address mapping without them having to ask for it at a later time. </p>

<p>Note that there is no way to authenticate that
a response is legitimate. The asking host does not
have any idea of what MAC address is associated with
the IP address. Hence, it cannot tell whether a host that responds
really has that IP address or is an imposter.</p>

<p>An <strong>ARP cache poisoning</strong> attack is one where
an attacker creates fake ARP responses
that contain the attacker’s MAC address and the target’s IP address.
This will direct any traffic meant for the target to the attacker.
It enables man-in-the-middle or denial of service attacks
since the real host will not be receiving any IP traffic.</p>

<p>There are several defenses against ARP cache poisoning.
One defense is to ignore replies that are not associated with requests.
However, you need to hope that the reply you get is a legitimate one
since an attacker may respond more quickly or perhaps launch a denial
of service attack against the legitimate host and then respond.</p>

<p>Another defense is to give up on ARP broadcasts and
simply use static ARP entries. This works but can be
an administrative nightmare since someone will have to keep
the list of IP and MAC address mappings and the addition of new machines
to the environment.</p>

<p>Finally, one can enable something called <strong>Dynamic ARP Inspection</strong>.
This essentially builds a local ARP table by using DHCP (Dynamic Host Configuration Protocol) Snooping
data as well as static ARP entries. Any ARP responses will be
validated
against DHCP Snooping database information or static ARP entries. This assumes that the environment uses DHCP instead of fixed IP address assignments.</p>

<h3 id="dhcpspoofing">DHCP spoofing</h3>

<p><em>Configure new devices on the LAN with your choice of DNS address, router address, etc.</em></p>

<p>When a computer joins a network, it needs to be configured for using the Internet Protocol (IP) on that network. This can be done automatically via <strong>DHCP</strong>, the <strong>Dynamic Host Configuration Protocol</strong>. It is used in practically every LAN environment and is particularly useful where computers (including phones) join and leave the network regularly, such as Wi-Fi hotspots.</p>

<p>A computer that joins a new network broadcasts a <strong>DHCP Discover</strong> message.
A DHCP server on the network picks up this request and sends back a response
that contains configuration information for this new computer on the network:</p>

<ul>
<li>IP address &#8211; the address given to the system</li>
<li>Subnet mask &#8211; which bits of the IP address identify the local area network</li>
<li>Default router &#8211; gateway to which all non-local datagrams will be routed</li>
<li>DNS servers &#8211; servers that tell you the IP address for a domain name</li>
<li>Lease time &#8211; how long the configuration is valid</li>
</ul>

<p>As with ARP, we have the problem that a computer does not know where
to go to for this information and has to rely on a broadcast query, hoping
that it gets a legitimate response.</p>

<p>With <strong>DHCP Spoofing</strong>, any system can pretend to be a DHCP server
and spoof responses that would normally be sent by a valid DHCP server.
This imposter can provide the new system with a legitimate IP address
but with false addresses for the gateway (default router) and DNS
servers. The result is that the imposter can field DNS requests, which
convert domain names to IP addresses and can also redirect any traffic
that leaves the local area network from the new machine.</p>

<p>As with ARP cache poisoning, the attacker may launch a denial of service
attack against the legitimate DHCP server to keep it from responding or
at least delay its responses.
If the legitimate server sends its response after the imposter,
the new host will simply ignore the response.</p>

<p>There aren&#8217;t many defenses against DHCP spoofing.
Some switches (such as those by Cisco and Juniper) support <strong>DHCP snooping</strong>.
This allows an administrator to configure specific switch
ports as “trusted” or “untrusted.&quot;
Only specific machines, those on trusted ports, will be
permitted to send DHCP responses. Any other DHCP responses will be dropped.
The switch will also use DHCP data to track client behavior
to ensure that hosts use only the IP address assigned to them
and that hosts do not generate fake ARP responses</p>

<h2 id="networkiplayer">Network (IP) layer</h2>

<p>The Internet Protocol (IP) layer is responsible for getting datagrams (packets) to their destination. It does not provide any guarantees on message ordering or reliable delivery. Datagrams may take different routes through the network and may be dropped by queue overflows in routers.</p>

<h3 id="sourceipaddressauthentication">Source IP address authentication</h3>

<p><em>Anyone can impersonate an IP datagram.</em></p>

<p>One fundamental problem with IP communication is that
there is absolutely no
source IP address authentication.
Clients are expected to use their own source IP address but
anybody can override this if they have administrative privileges on their system by using a raw sockets interface.</p>

<p>This enables one to forge messages to appear that they come
from another system. Any software that authenticates requests
based on their IP addresses will be at risk.</p>

<h3 id="anonymousdenialofservice">Anonymous denial of service</h3>

<p>The ability to set an arbitrary source address in an IP datagram can be used for <strong>anonymous denial of service attacks</strong>.
If a system sends a datagram that generates an error,
the error will be sent back to the source address that
was forged in the query.
For example, a datagram sent with a small time-to-live,
or TTL, value will cause a router that is hit when the
TTL reaches zero to respond back with an <em>ICMP</em> (Internet Control Message Protocol)
<em>Time to Live exceeded</em> message.
Error responses will be sent to the forged source IP address
and it is possible to send a vast number of such
messages from many machines (by assembling a botnet) across many networks, causing the errors to all target a single system.</p>

<h3 id="routers">Routers</h3>

<p>Routers are nothing more than computers with multiple network links and often with special purpose hardware to facilitate the rapid movement of packets across interfaces. They run operating systems and have user interfaces for administration. As with many other devices that people don&#8217;t treat as &#8220;real&#8221; computers, there is a danger that they routers will have simple or even default passwords. Moreover, owners of routers may not be nearly as diligent in keeping the operating system and other software updated as they are with their computers.</p>

<p>Routers can be subject to some of the same attacks as computers. Denial of service (DoS) attacks can keep the router from doing its job. One way this is done is by sending a flood of ICMP datagrams. The Internet Control Message Protocol is typically used to send routing error messages and updates and a huge volume of these can overwhelm a router. Routers may also have input validation bugs and not handle certain improper datagrams correctly.</p>

<p><strong>Route table poisoning</strong> is the modification of the router&#8217;s routing table either by breaking into a router or by sending route update datagrams over an unauthenticated protocol.</p>

<h2 id="transportlayerudptcp">Transport layer (UDP, TCP)</h2>

<p>UDP and TCP are transport layer protocols that allow
applications to establish communication channels with
each other. Each endpoint of such a channel is identified
by a port number (a 16-bit integer that has nothing to
do with Ethernet switch ports). The port number allows the operating system to direct traffic to the proper socket.
Hence, both TCP and
UDP packets contain not only source and destination
addresses but also source and destination ports.</p>

<p>UDP, the User Datagram Protocol,
is stateless, connectionless, and unreliable.</p>

<p>As we saw with IP source address forgery, anybody
can send UDP messages with forged source IP addresses.</p>

<p>TCP, the Transmission Control Protocol, is
stateful, connection-oriented, and reliable.
Every packet contains a sequence number (byte offset) and
the operating system assembles received packets into their correct order.
The receiver also sends acknowledgements so that any
missing packets are retransmitted.</p>

<p>To handle in-order, reliable communication, TCP needs to establish state at both endpoints.
It does this through a connection setup process that
comprises a three-way handshake.</p>

<ol>
<li><p><strong>SYN</strong>: Client sends a SYN segment
The client selects a random <strong>initial sequence number</strong> (<code>client_isn</code>).</p></li>
<li><p><strong>SYN/ACK</strong>: Server sends a SYN/ACK
The server receives the SYN segment and knows that a
client wants to connect to it. It allocates memory
to store connection state and to hold out-of-order
segments. The server generates an initial sequence
number (<code>server_isn</code>) for its side of the data stream. This is also a
random number. The response also contains an acknowledgement
with the value <code>client_isn+1</code>.</p></li>
<li><p><strong>ACK</strong>: Client sends a final acknowledgement
The client acknowledges receipt of the SYN/ACK message by
sending a final ACK message that contains an acknowledgement
number of <code>server_isn+1</code>.</p></li>
</ol>

<p>Note that the initial sequence numbers are <strong>random</strong> rather than starting at zero as one might expect. There are two reasons for this.</p>

<p>The primary reason is that message delivery times on an IP network are unpredictable and it is possible that a recently-closed connection may receive delayed messages, confusing the server on the state of that connection. </p>

<p>The security-sensitive reason
is that if sequence numbers were predictable then it would be quite easy to launch a <strong>sequence number prediction attack</strong> where an attacker
would be able to guess at likely sequence numbers on a connection
and send masqueraded packets that will appear to be part of the
data stream. Random sequence numbers do not make the problem
go away but make it more challenging to launch the attack,
particularly if the attacker does not have the ability to
see traffic on the network.</p>

<h3 id="synflooding">SYN flooding</h3>

<p>In the second step of the three-way handshake, the server
is informed that a client would like to connect and allocates
memory to manage this connection. Given that kernel memory
is a finite resource, the operating system will allocate only a finite number of TCP buffers in its TCP queue. After that, it will refuse to accept any new connections.</p>

<p>In the <strong>SYN flooding</strong> attack, the attacker sends a large
number of SYN segments to the target. These SYN messages
contain a forged source address of an unreachable host,
so the target&#8217;s SYN/ACK responses never get delivered anywhere.
The handshake is never completed but the operating system
has allocated resources for this connection. Depending on
the operating system, it might be a minute or much longer
before it times out on waiting for a response and cleans up
these pending connections. Meanwhile, all TCP buffers have
been allocated and the operating system refuses to accept
any more TCP connections, even if they are from a legitimate source.</p>

<p>SYN flooding attacks cannot be prevented completely. One
way of lessening their impact is the use of <strong>SYN cookies</strong>.
With SYN cookies, the server does not allocate buffers &amp; TCP state
when a SYN segment is received. It responds with a SYN/ACK and
creates an initial sequence number that is a hash of several
known values:</p>

<pre><code>hash(src_addr, dest_addr, src_port, dest_port, SECRET)
</code></pre>

<p>The &#8220;SECRET&#8221; is not shared with anyone; it is local to the operating
system. When (if) the final ACK comes back from the client,
the server needs to validate the acknowledgement number. Normally
this requires comparing the number to the stored server initial
sequence number plus 1. We did not allocate space to store
this value but we can recompute the number by re-generating the hash,
adding one, and comparing it to the acknowledgement number in the
message.
If it is valid, the kernel believes it was not the victim of a SYN
flooding attack and allocate resources necessary for managing
the connection.</p>

<h3 id="tcpreset">TCP Reset</h3>

<p>A somewhat simple attack is to
send a <strong>RESET</strong> (RST) segment to an open TCP socket.
If the server sequence number is correct then the connection will close.
Hence, the tricky part is getting the correct sequence number to make it look like the RESET
is part of the genuine message stream.</p>

<p>Sequence numbers are 32 bit values. The chance of successfully picking
the correct sequence number is tiny: 1 in 2<sup>32</sup>, or approximately
one in four billion.
However, many systems will accept a large range of sequence numbers that
are approximately in the correct range to account for the fact that packets may arrive out of orders so they shouldn&#8217;t necessarily be rejected
just because the sequence number is not exactly correct.
This can reduce the search space tremendously and an
attacker can send a flood of RST packets with varying sequence
numbers and a forged source address until the connection is broken.</p>

<h2 id="routingprotocols">Routing protocols</h2>

<p>The Internet was designed to connect multiple independently-managed
networks, each of which may use different hardware. Routers connect local area
networks as well as wide area networks together.
A collection of consecutive IP addresses (most significant bits, called <strong>prefixes</strong>)
as well as the underlying routers and network infrastructure, all managed as one administrative entity, is called an
<a href="https://www.cs.rutgers.edu/~pxk/352/notes/autonomous_systems.html">Autonomous System</a> (<strong>AS</strong>).
For example, the part of the Internet managed by Comcast constitutes an autonomous system (Comcast actually has 42 in different regions).
The networks managed by Verizon happen to constitute a few autonomous systems as well. For purposes of our discussion, think of an AS ISPs or large data centers such as Google or Amazon (BTW, Rutgers is an Autonomous System: AS46).</p>

<p>The routers within an autonomous system need to share routing information
so that those routers can route packets efficiently toward their destination.
An Interior Gateway Protocol is used within an autonomous system. The most common
is OSPF, Open Shortest Path First. While security issues exist within autonomous
system, we will turn our attention to the sharing of information between autonomous
systems.</p>

<p>Routers that are connected to routers in other ASes use an Exterior Gateway Protocol (EGP) called the <strong>Border
Gateway Protocol</strong>, or <strong>BGP</strong>. With BGP, each autonomous system exchanges
routing and reachability information with the autonomous systems with which
it connects. For example, Comcast can tell Verizon what parts of the Internet
it can reach. BGP uses a distance vector routing algorithm to enable the routers
to determine the most efficient path to use to
send packets that are destined for other networks. Unless an administrator
explicitly configures a route, BGP will pick the shortest route.</p>

<h3 id="bgphijacking">BGP Hijacking</h3>

<p>So what are the security problems with BGP?
Edge routers use BGP to send <em>route advertisements</em> to routers
they are connected to on neighboring autonomous systems. An advertisement
is a list of IP address prefixes the AS can reach (shorter prefixes mean a bigger range of
addresses) and the distance (number of hops) to each group of systems. </p>

<p>These are TCP messages
with no authentication, integrity checks, or encryption. With <strong>BGP hijacking</strong>, a malicious
party that has access to the network link or a connected router can inject advertisements for arbitrary routes. This information
will propagate throughout the Internet and can cause routers throughout the Internet to send IP datagrams to the attacker, with the belief that is the shortest path to the destination.</p>

<p>A BGP attack can be used for
eavesdropping (direct network traffic to a specific network by telling
everyone that you&#8217;re offering a really short path) or a denial of service
(DoS) attack (make parts of the network unreachable by redirecting traffic
and then dropping it. There are currently close to 33,000 autonomous systems and most have multiple administrators. We live in the hope that none are malicious and that all routers are properly configured and properly secured.</p>

<p>It is difficult to change BGP since tens of thousands of independent entities use
it worldwide. Two partial solutions to this problem emerged.
the <strong>Resource Public Key Infrastructure</strong> (<strong>RPKI</strong>) framework
simply has each AS get an X.509 digital certificate from a trusted
entity (the Regional Internet Registry).
Each AS signs its list of route advertisements with its private key
and any other AS can validate that list of advertisements using
the AS&#8217;s certificate. </p>

<p>A related solution is <strong>BGPsec</strong>, which is still a draft
standard. Instead of signing an individual
AS&#8217;s routes, every BGP message between ASes is signed.</p>

<p>Both solutions require every single AS to employ this solution. If
some AS is willing to accept untrusted route advertisements but will
relay them to other ASes as signed messages then integrity is meaningless. Moreover, most BGP hijacking incidents took place because legitimate system administrators misconfigured route advertisements either accidentally or on purpose. They were not the actions of attackers that hacked into a router.</p>

<p>A high profile BGP attack occurred against YouTube in 2008.
Pakistan Telecom received a censorship order from the telecommunications ministry to block YouTube
traffic to the country.
The company sent spoofed BGP messages claiming to be the best route for the range
of IP addresses used by YouTube. It used a longer address prefix than the one
advertised by YouTube (longer prefix = fewer addresses). Because the longer
prefix was deemed to be more specific, BGP gave it a higher priority. Within minutes,
routers worldwide were directing their YouTube requests to Pakistan Telecom,
which would simply drop them.</p>

<h2 id="domainnamesystemdns">Domain Name System (DNS)</h2>

<p>The Domain Name System (DNS) is a Hierarchical service that maps
Internet domain names to IP addresses.
A user&#8217;s computer runs the DNS protocol via a
program known as a <strong>DNS stub resolver</strong>.
It first checks a local file for specific preconfigured name-to-address mappings.
Then it checks its cache of previously-found mappings. Finally,
it contacts an external DNS resolver, which is usually located
at the ISP or is run as a public service, such as Google Public DNS or OpenDNS.</p>

<p>We trust that the name-to-address mapping is legitimate.
Web browsers, for instance, rely on this to enforce their <em>same-origin</em>
policy. However, DNS queries and responses are sent using UDP
with no authentication or integrity checks.
The only check is that each DNS query contains a Query ID (QID).
A DNS response must have a matching QID so that the client can match
it to the query.
These responses can be intercepted and modified or just forged.
Malicious responses can return a different IP address
that will direct IP traffic to different hosts</p>

<p>A solution called <strong>DNSsec</strong> has been proposed. It is a secure
extension to the DNS protocol that provide authenticated requests &amp; responses.
However, few sites support it.</p>

<h3 id="pharmingattack">Pharming attack</h3>

<p>A <strong>pharming attack</strong> is an attack on the configuration information
maintained by a DNS server &#8211;either modifying the information used
by the local DNS resolver or modifying that of a remote DNS server.
By changing the name to IP address mapping, an attacker can cause
software to send packets to the wrong system.</p>

<p>The most direct form of a pharming attack is to modify the local
<code>hosts</code> file. This is the file (<code>/etc/hosts</code> on Linux, BSD, and
macOS systems; <code>c:\Windows\System32\Drivers\etc\hosts</code> on Windows)
that contains mappings between domain names and IP addresses. If
an entry is found here, the system will not bother checking a remote
DNS server.</p>

<p>Alternatively, malware may modify the DNS server settings on a system
so that it would contact an attacker&#8217;s DNS server, which can provide
the wrong IP address for certain domain names. </p>

<h3 id="dnscachepoisoningdnsspoofingattack">DNS cache poisoning (DNS spoofing attack)</h3>

<p>DNS queries first check the local host&#8217;s DNS cache to see if
the results of a past query have been cached. This yields a huge
improvement in performance since a network query can be avoided.
If the cached name-to-address mapping is invalid, then
the wrong IP address is returned. Modifying this cached
mapping is called <strong>DNS cache poisoning</strong>, also known as <strong>DNS spoofing</strong>.
In the general case, DNS cache poisoning refers to any mechanism where an attacker is able to provide malicious responses to DNS queries.
One way that DNS cache poisoning is done is via
JavaScript on a malicious website. </p>

<p>The browser requests access to a legitimate
site. For example, a.bank.com. Because the
system does not have the address of a.bank.com cached, it sends
a DNS query to an external DNS resolver using the DNS protocol.
The query includes a query ID (QID) x<sub>1</sub>.
At the same time that the request for a.bank.com is made,
JavaScript launches an attacker thread that sends
256 responses with random QIDs (y<sub>1</sub>. y<sub>2</sub>, &#8230;}.
Each of these DNS responses tells the server that the DNS
server for bank.com is at the attacker&#8217;s IP address.
If one of these responses happens to have a matching QUD,
the host system will accept it as truth that all
future queries for anything at bank.com should be directed
to the name server for bank.com, which is run by the attacker.
If the responses don&#8217;t work, the script can try again
with a different sub-domain, b.bank.com. It might take many
minutes, but there is a high likelihood that the attack
will eventually succeed.</p>

<p>There are two defenses against this attack but
they both require non-standard actions that will need
to be coded into the system.
One is to randomize the source port number of the query.
Since the attacker does not get to see the query, it
will not know where to send the bogus responses. There are
2<sup>16</sup> (65,536) ports to try.
The second defense is to force all DNS queries to be
issued twice. The attacker will have to guess the 32-bit
query ID twice in a row and the chances of doing that
successfully are infinitesimally small.</p>

<p><strong>Summary</strong>: An attacker can run a local DNS server that will attempt to provide spoofed DNS responses to legitimate domain name lookup requests. If the query ID numbers of the fake response match those of a legitimate query (trial and error), the victim will get the wrong IP address, which will redirect legitimate requests to an attacker&#8217;s service.</p>

<h3 id="dnsrebinding">DNS Rebinding</h3>

<p>Web application security is based on the <strong>same-origin</strong> policy. Browser scripts can access cookies and other data on pages only if they share the same origin, which is the combination of URI (protocol), host name, and port number. The underlying assumption is that resolving a domain name takes you to the correct server.</p>

<p>The <strong>DNS rebinding</strong> attack allows JavaScript code on a malicious web page to access private IP addresses in the victim&#8217;s network. The attacker configures the DNS entry for a domain name to have a short time to live (TTL). When the victim&#8217;s browser visits the page and downloads JavaScript from that site, that JavaScript code is allowed to interact with the domain thanks to the same origin policy. However, right after downloading the script, the attacker can reconfigure the DNS server so that future queries will return an address in the internal network. The JavaScript code can then try to request resources from that system since, as far as the browser is concerned, the origin is the same because the name of the domain has not changed.</p>

<p><strong>Summary</strong>: short time-to-live values in DNS allow an attacker to change the address of a domain name so that scripts from that domain can now access resources inside the private network.</p>

<h3 id="dnsamplificationattack">DNS amplification attack</h3>

<p>We have seen how source address spoofing can be used to
carry out an anonymous denial of service (DoS) attack. Ideally,
to overload a system, the attacker would like to send a small amount of data
that would create a large response that would be sent to the target.
This is called <strong>amplification</strong>. An obvious method would be to send
a URL request over HTTP that will cause the server to respond with
a large page reply. However, this does not work as HTTP uses TCP and
the target would not have the TCP session established.
DNS happens to be a UDP-based service. <strong>DNS amplification</strong> uses
a collection of compromised systems that will carry out the
attack (a <strong>botnet</strong>). Each system will send a small DNS query
using a forged source address.
These systems can contact their
own ISP&#8217;s DNS servers since the goal is not to overwhelm any DNS
server.
The query asks for &#8220;ANY&#8221;, a request for all known
information about the DNS zone.
Each such query will cause the DNS server to send
back a far larger reply.</p>

<div class="footnotes">
<hr />
<ol>

<li id="fn:1">
<p>MAC = <em>Media Access Control</em>_ and refers to the hardware address of the Ethernet device. <a href="#fnref:1" title="return to article" class="reversefootnote">&#160;&#8617;</a></p>
</li>

</ol>
</div>


<h1 id="virtualprivatenetworksvpns">Virtual Private Networks (VPNs)</h1>

<p>Suppose we want to connect two local area networks in geoagraphically-separated
areas together. For instance, we might have a company with locations in New York
and in San Francisco. One way of doing this is to get a dedicated private network
link between the two points. Many phone companies and network providers offer a
private line service but it can be extremely expensive and is not feasible in many
circumstances, such as if one of your endpoints is in the Amazon cloud rather
than at your physical location.o</p>

<p>Instead, we can use the public Internet to communicate between the two locations.
Our two subnets will often have private IP addresses (such as 192.168.x.x), which
are not routable over the public internet. To overcome this, we can use
a technique called <strong>tunneling</strong>.
Tunneling is the process of encapsulating an IP datagram within another IP
datagram. An IP datagram in one subnet (a local area network in one of our locations)
that is destined to an address on the remote subnet will be directed to a gateway
router. There, it will be treated as payload (data) and packaged within an IP datagram
whose destination is the IP address of the gateway router at our other location.
This datagram is now routed over the public Internet. The source and destination
addresses of this outer datagram are the gateway routers at both sides.</p>

<p>IP networking relies on store-and-forward routing.
Network data passes through routers, which are often unknown and may be untrustworthy.
We have seen that
routes may be altered to pass data through malicious hosts or directed to malicious
hosts that accept packets destined for the legitimate host.
Even with TCP connections, data can be modified or redirected and sessions can be hijacked.
We also saw that there is no source authentication on IP packets: a host
can place any address it would like as the source.
What we would like is the ability to communicate securely, with the assurance
that our traffic cannot be modified and that we are truly communicating
with the correct endpoints.</p>

<p><strong>Virtual private networks</strong> (<strong>VPNs</strong>) take the concept of tunneling
and safeguard the encapsulated data by adding a MAC (message authentication code)
so that we can detect if the data is modified and encrytion so that others
cannot read the data. This way, VPNs
allow separate local area networks to communicate
securely over the public Internet.</p>

<p><strong>IPsec</strong> is a popular VPN protocol that is really a set of two protocols. </p>

<ol>
<li><p>The IPsec <strong>Authentication Header</strong> (<strong>AH</strong>) is an IPsec protocol that does <em>not</em> encrypt data but simply
affixes a message authentication code to each datagram. It ensures the integrity of the each datagram.</p></li>
<li><p>The <strong>Encapsulating Security Payload</strong> (<strong>ESP</strong>), which provides integrity checks and also encryts
the payload, ensuring secrecy.</p></li>
</ol>

<p>IPsec can operate in tunnel mode or transport mode. In both cases, IPsec communciates at the same
layer as the Internet Protocol. That is, it is not used by applications to communciate with one another
but rather by routers or operating systems to direct an entire stream of traffic.</p>

<p><strong>Tunnel mode VPNs</strong> provide network-to-network or host-to-network communication.
The communication takes place between either two VPN-aware gateway routers or from a host to a VPN-aware router.
The entire datagram is treated like payload and encapsulated within a datagram that is sent over the Internet
to the remote gateway. That gateway receives this VPN datagram, extracts the payload, and routes it on the internal network
where it makes its way to the target system.</p>

<p><strong>Transport mode VPNs</strong> provide communication between two hosts. In this case, the IP header is not modified
but data is protected. Note that, unlike transport layer security (TLS), which we examine later, setting up
a transport mode VPN will protect all data streams between the two hosts. Applications are unaware that a VPN is
in place.</p>

<h2 id="authenticationheaderah">Authentication Header (AH)</h2>

<p>The <strong>Authentication Header</strong> (<strong>AH</strong>) protocol guarantees the integrity and authenticity of IP packets.
AH adds an extra chunk of data (the authentication header) with a MAC to the IP datagram.
Anyone with knowledge of the key can create the MAC or verify it.
This ensures message integrity since an attacker will not be
able to modify message contents and have the HMAC remain valid. Attackers will also not be able to
forge messages because they will not know the key needed to create a valid MAC. Every AH
also has a sequence number that is incremented for each datagram that is transmitted, ensuring
that messages are not inserted, deleted, or replayed.</p>

<p>Hence, IPsec AH protects messages from tampering, forged addresses, and replay attacks.</p>

<h2 id="encapsulatingsecuritypayloadesp">Encapsulating Security Payload (ESP)</h2>

<p>The <strong>Encapsulating Security Payload</strong> (<strong>ESP</strong>) provides the same integrity assurance but also adds <strong>encryption</strong> to the payload to ensure confidentiality. Data is encrypted with a symmetric cipher (usually AES).</p>

<h2 id="ipseccryptographicalgorithms">IPsec cryptographic algorithms</h2>

<h3 id="authentication">Authentication</h3>

<p>An IPsec session begins with authenticating the endpoints. IPsec supports the use of X.509 digital
certificates or the use of pre-shared keys. Digital certificates contain the site&#8217;s public key
and allow us to validate the identity of the certificate if we trust the issuer (the certification
authority, or CA). We authenticate by proving that can take a nonce that the other side encrypted with
our public key and decrypt it using our private key. A pre-shared key means that both sides configured
a static shared secret key ahead of time. We prove that we have the key in a similar manner: one side
creates a nonce and asks the other side to encrypt it and send the results. THen the other side does
the same thing.</p>

<h3 id="keyexchange">Key exchange</h3>

<p>HMAC message authentication codes and encryption algorithms both require the use of secret keys.
IPsec uses Diffie-Hellman to create random shared session keys. Diffie-Hellman makes it quick to
generate a public-private key pair that is needed to derive a common key ao there is no dependence
on long-term keys, assuring forward secrecy.</p>

<h3 id="confidentiality">Confidentiality</h3>

<p>In IPsec ESP, the payload is encrypted using either AES-CBC or 3DES-CBC. CBC is cipher-block chaining, which
has the property that the ciphertext of each datagram is dependent on all previous datagrams, ensuring that
datagrams cannot be substituted from old messages.</p>

<h3 id="integrity">Integrity</h3>

<p>IPsec uses HMAC, a form of a message authentication code that
uses a cryptographic hash function and a shared secret key.
It supports either SHA&#8211;1 or SHA&#8211;2 hash functions.</p>

<p>IPsec Authentication Header mode is rarely used since the overhead of encrypting
data these days is quite low and ESP provides both encryption in addition to authentication and integrity.</p>

<h1 id="transportlayersecuritytls">Transport Layer Security (TLS)</h1>

<p>Virtual Private Networks were designed to operate at the network layer.
They were designed to connect networks together. Even with transport mode connectivity,
they tunnel all IP traffic and do not differentiate one data stream from another.
They do not solve the problem of an application needing authenticated, tamper-proof,
and encrypted communications to another application.</p>

<p><strong>Secure Sockets Layer</strong> (<strong>SSL</strong>) was created as a layer of software above TCP
that provides authentication, integrity, and encrypted communication while preserving
the abstraction of a sockets interface to applications. An application sets up an SSL session
to a service. After that, it simply sends and receives data over a socket just like it would
with the normal sockets-based API that operating systems provide. The programmer
does not have to think about network security. As SSL evolved, it morphed into a new version called <strong>TLS</strong>, <strong>Transport
Layer Security</strong>. While SSL is commonly used in conversation, all current
implementations are TLS.</p>

<p>Any TCP-based application that may not have addressed network security can be
security-enhanced by simply using TLS. For example, the standard email protocols,
SMTP, POP, and IMAP, all have TLS-secured interfaces. Web browsers use
HTTP, the Hypertext Transfer
Protocol, and also support HTTPS, which is the exact same protocol but uses
A TLS connection.</p>

<p>TLS has been designed to provide:</p>
<dl>
<dt>Data encryption</dt>
<dd>Symmetric cryptography is used to encrypt data.</dd>

<dt>Data integrity</dt>
<dd>Ensure that we can detect if data in transit has not been modified. TLS includes a MAC with transmitted data.</dd>

<dt>Authentication</dt>
<dd>TLS provides mechanisms to authenticate the endpoints prior to sending data. Authentication is optional and can be unidirectional (the client may just authenticate the server), unidirectional (each side authenticates the other), or none (in which case we just exchange keys but do not validate identities).</dd>

<dt>Key exchange</dt>
<dd>After authentication, TLS performs a key exchange so that both sides can obtain random shared session keys. TLS creates separate keys for each direction of communication (encryption keys for client-to-server and server-to-client data streams) and separate keys for data integrity (MAC keys for client-to-server and server-to-client streams).</dd>

<dt>Interoperability &amp; evolution</dt>
<dd>TLS was designed to support many different key exchange, encryption, integrity, &amp; authentication protocols. The start of each session enables the protocol to negotiate what protocols to use for the session.</dd>
</dl>


<h2 id="tlssub-protocols">TLS sub-protocols</h2>

<p>These features are implemented in two sub-protocols within TLS:</p>
<dl>
<dt>1. Authentication and key exchange</dt>
<dd>Authentication uses public key cryptography with X.509 certificates to authenticate a system. Both the client and
server can present their X.509 digital certificates. TLS validates the signature of the certificate and
uses nonce-based public key authentication to validate that each party has the
corresponding private key.</dd>

<dd>
<p>Key exchange supports several options. Ephemeral Diffie-Hellman key exchange is the most common since it supports the efficient generation of shared keys and there is no long-term key storage, providing forward secrecy. TLS can accommodate other key exchange techniques as well, including DIffie-Hellman with static keys, RSA public key-based key exchange, and pre-shared static keys.</p></dd>

<dt>2. Communication</dt>
<dd>Data encryption uses symmetric cryptography and supports a variety of algorithms, including AES GCM, AES CBC, ARIA (GCM/CBC), and ChaCha20. AES is the Advanced Encryption Standard. CBC is cipher block chaining, which makes each ciphertext block a function of the preceding one. GCM is Galois/Counter Mode, an alternative to CBC that encrypts an incrementing counter and exclusive-ors it with a block of plaintext. ARIA is a South Korean standard encryption algorithm that is similar to AES. ChaCha20 is an encryption algorithm that is generally more efficient than AES on low-end processors.</dd>

<dd>
<p>Data integrity is provided by a message authentication code (MAC) that is attached to each block of data. TLS allows the choice of several, including HMAC-MD5, HMAC-SHA1, HMAC-SHA256/384, and Poly1305.</p></dd>
</dl>


<h2 id="tlsprotocol">TLS protocol</h2>

<p>The steps in a TLS session are:</p>

<ol>
<li><p>The client connects to the server and sends information about its version and the ciphers it supports. It is up to the
client and server to negotiate for the ones they will use.</p></li>
<li><p>The server responds with its X.509 certificate,
the protocol version and ciphers it is willing to use, and, possibly, a request for a client certificate.</p></li>
<li><p>The client validates the integrity of the server&#8217;s certificate by validating the signature of the certificate. If the client trusts the server&#8217;s CA, the client can validate the authenticity of the server. Otherwise, the client can simply validate that the server owns the corresponding private key.</p></li>
<li><p>The client generates random session keys and sends them to the server via a Diffie-Hellman key exchange.</p></li>
<li><p>Optionally, the client responds with its certificate.</p></li>
<li><p>If the client responds with its certificate, the server validates the certificate and the client.</p></li>
<li><p>The client and server can now exchange data. Each message is first compressed and then
encrypted with a symmetric algorithm. An HMAC (hash MAC) for the message is also sent to allow
the other side to validate message integrity.</p></li>
</ol>

<p>TLS is widely used and generally considered secure if strong cryptography is used.
Its biggest problem was a man-in-the-middle attack where the attacker would be able to send a message
to renegotiate the protocol and choose one that disables encryption.
Another attack was a denial-of-service attack where an attacker initiates a TLS connection
but keeps requesting a regeneration of the encryption key, using up the server&#8217;s resources
in the process. Both of these have been fixed.</p>

<h2 id="unidirectionalvs.mutualauthentication">Unidirectional vs. mutual authentication</h2>

<p>TLS supports <strong>mutual authentication</strong>.
To implement authentication, the server sends the client its X.509 digital certificate so the client can authenticate the server by having the server prove it knows the private key. TLS also supports <strong>mutual authentication</strong>: the client will send its X.509 certificate to the server so the server can authenticate the client.</p>

<p>One notable aspect of TLS sessions is that, in most cases, only the server will present a certificate.
Hence, the server will not authenticate or know the identity of the client.
Client-side certificates have been problematic.
Generating keys and obtaining trustworthy certificates is not an easy process for users.
A user would have to install the certificate and the corresponding private
key on every system she uses. This would not be practical for shared systems.
Moreover, if a client did have a certificate, any server can request it during
TLS connection setup, thus obtaining the identity of the client. This could
be desirable for legitimate banking transactions but not for sites where a user would like
to remain anonymous.
We generally rely on other authentication mechanisms, such as the password
authentication protocol, but carry them out over TLS&#8217;s secure communication channel.</p>

<h1 id="firewalls">Firewalls</h1>

<p>A <strong>firewall</strong> protects the junction between an untrusted
network (e.g., external Internet) and a trusted network (e.g., internal network).
Two approaches
to firewalling are <strong>packet filtering</strong> and <strong>proxies</strong>.
A <strong>packet filter</strong>, or <strong>screening router</strong>,
determines not only the route of a packet but whether the packet
should be dropped based on contents in the IP header, TCP/UDP header,
and the interface on which the packet arrived. It is usually implemented
inside a <strong>border router</strong>, also known as the <strong>gateway router</strong> that
manages the flow of traffic between the ISP and internal network.
The basic principle of firewalls is to never have a direct inbound
connection from the originating host from the Internet to an internal
host; all traffic must flow through a firewall and be inspected.</p>

<p>The packet filter evaluates a set of rules to determine whether to <strong>drop</strong>
or <strong>accept</strong> a packet. This set of rules forms an <strong>access control list</strong>,
often called a <strong>chain</strong>. Strong security follows a <strong>default deny</strong> model,
where packets are dropped unless some rule in the chain specifically permits them.</p>

<p><strong>First-generation packet filters</strong> implemented <strong>stateless
inspection</strong>. A packet is examined on its own with no context based
on previously-seen packets.</p>

<p><strong>Second-generation packet filters</strong> track TCP connections and other information from previous connections. These <strong>stateful packet inspection</strong> (<strong>SPI</strong>) firewalls allow the router to keep track of outstanding TCP connections. For instance:</p>

<ul>
<li><p>They can block TCP data traffic if a connection setup did not take place to avoid sequence number prediction attacks. </p></li>
<li><p>They can track that a connection has been established by a client to a remote server and allow return traffic to that client (which is essential for any interaction by someone inside the network with external services). </p></li>
<li><p>They can track connectionless UDP and ICMP messages and allow responses to be sent back to clients in the internal network. DNS queries and pings (ICMP echo-reply messages) are examples of these.</p></li>
<li><p>They also and understand the relationship between packets. For example, when a client establishes an FTP (file transfer protocol) connection to a server on port 21, the server establishes a connection back to the client on a different port when it needs to send data. </p></li>
</ul>

<p>Packet filters traditionally do not look above the transport layer (UDP and TCP protocols and port numbers). <strong>Third-generation packet filters</strong> incorporate
<strong>deep packet inspection</strong>
(<strong>DPI</strong>), which allows a firewall to examine application data
as well and make decisions based on its contents. Deep packet inspection
can validate the protocol of an application as well as check for malicious
content such as malformed URLs or other security attacks. DPI is generally
considered to be part of Intrusion Prevention Systems. Examples are detecting application-layer protocols such as HTTP and then applying application-specific filters, such as checking for suspicious URLs or disallowing the download of certain ActiveX or Java applets.</p>

<p>Deep Packet Inspection (DPI) firewalls evolved to <strong>Deep Content Inspection</strong> (<strong>DCI</strong>) firewalls. These use the same concept but are capable of buffering large chunks of data from multiple packets that contain an entire object and acting on it, such as unpacking base64-encoded content from web and email messages and performing a signature analysis for malware.</p>

<h3 id="applicationproxies">Application proxies</h3>

<p>An <strong>application proxy</strong> is software that presents the same protocol to
the outside network as the application for which it is a proxy.
For example, a mail server proxy will listen on port 25 and understand
SMTP, the <em>Simple Mail Transfer Protocol</em>. The primary job of the proxy is
to <strong>validate</strong> the application protocol and thus guard against protocol
attacks (extra commands, bad arguments) that may exploit bugs in the service. Valid requests are then regenerated
by the proxy to the real application that is running on another server and is
not accessible from the outside network.</p>

<p>Application proxies are usually installed on <strong>dual-homed hosts</strong>. This is a term for a system that has two &#8220;homes&#8221;, or network interfaces: one for the external network and another for the internal network. Traffic does not pass between the two networks.
The proxy is the only one that can communicate with the internal network.
Unlike DPI, a proxy may modify the data stream,
such as stripping headers or modifying machine names. It may also restructure
the commands in the protocol used to communicate with the actual servers (that is,
it does not have to relay everything that it receives).</p>

<h3 id="dmzs">DMZs</h3>

<p>A typical firewalled environment is a <strong>screened subnet</strong>
architecture, with a separate subnet for systems that run externally-accessible
services (such as web servers and mail servers) and another one for internal
systems that do not offer services and should not be accessed from the outside.
The subnet that contains externally-accessible services is called the <strong>DMZ</strong> (<strong>demilitarized zone</strong>).
The DMZ contains all the hosts that may be
offering services to the external network (usually the Internet).
Machines on the internal network are not accessible from the Internet.
All machines within an organization will be either in the DMZ or
in the internal network.</p>

<p>Both subnets will be protected by screening routers.
They will ensure that no packet
from the outside network is permitted into the inside network.
Logically, we can
view our setup as containing two screening routers:</p>

<ol>
<li><p>The <strong>exterior router</strong> allows IP packets
 only to the machines/ports in the DMZ that are offering valid
 services. It would also reject any packets that are masqueraded to
 appear to come from the internal network.</p></li>
<li><p>The <strong>interior router</strong>
 allows packets to only come from designated machines in the DMZ that
 need to access services in the internal network. Any packets
 not targeting the appropriate services in the internal network will
 be rejected. Both routers will generally allow traffic to flow from
 the internal network to the Internet, although an organization may
 block certain services (ports) or force users to use a proxy (for
 web access, for example).</p></li>
</ol>

<p>Note that the two screening routers may be easily replaced with
a single router since filtering rules can specify interfaces. Each rule can thus
state whether an interface is the DMZ, internal network,
or Internet (ISP).</p>

<h3 id="host-basedfirewalls">Host-based firewalls</h3>

<p>Firewalls generally intercept all packets entering or leaving a local area network.
A <strong>host-based firewall</strong>, on the other hand, runs on a user&#8217;s computer.
Unlike network-based firewalls, a host-based firewall can associate
network traffic with individual applications.
Its goal is to prevent malware from accessing the network. Only approved
applications will be allowed to send or receive network data.
Host-based firewalls are particularly useful in light of <strong>deperimiterization</strong>:
the boundaries of external and internal networks are sometimes fuzzy
as people connect their mobile devices to different networks and import
data on flash drives. A concern with host-based firewalls is that
if malware manages to get elevated privileges, it may be able to shut
off the firewall or change its rules.</p>

<h3 id="intrusiondetectionpreventionsystems">Intrusion detection/prevention systems</h3>

<p>An enhancement to screening routers is the use of <strong>intrusion detection systems</strong> (<strong>IDS</strong>). Intrusion
detection systems are often parts of DPI firewalls and try to identify malicious behavior. There are three forms of IDS:</p>

<ol>
<li><p>A <strong>protocol-based IDS</strong> validates specific network protocols for
conformance. For example, it can implement a state machine to ensure that messages
are sent in the proper sequence, that only valid commands are sent, and that replies match
requests.</p></li>
<li><p>A <strong>signature-based IDS</strong> is similar to a PC-based virus checker. It
scans the bits of application data in incoming packets to try to discern if there
is evidence of &#8220;bad data&#8221;, which may include malformed URLs, extra-long strings
that may trigger buffer overflows, or bit patterns that match known viruses.</p></li>
<li><p>An <strong>anomaly-based IDS</strong> looks for statistical aberrations in network activity.
Instead of having predefined patterns, normal behavior is first measured and used
as a baseline. An unexpected use of certain protocols, ports, or even amount of
data sent to a specific service may trigger a warning.</p></li>
</ol>

<p>Anomaly-based detection implies that we know <em>normal behavior</em> and flag
any unusual activity as bad. This is difficult since it is hard to
characterize what normal behavior is, particularly since normal behavior
can change over time and may exhibit random network accesses (e.g., people
web surfing to different places). Too many false positives will annoy
administrators and lead them to disregard alarms.</p>

<p>A signature-based system employs <strong>misuse-based detection</strong>.
It knows bad behavior: the rules that define invalid packets or invalid
application layer data (e.g., ssh root login attempts). Anything else is
considered good.</p>

<p>Intrusion Detection Systems (IDS) monitor traffic entering and leaving the network and report any discovered problems.
<strong>Intrusion Prevention Systems</strong> (<strong>IPS</strong>) serve the same function but are positioned to sit between two networks like a firewall and can actively block traffic that is considered to be a threat or policy violation. </p>

<table>
<colgroup>
<col style="text-align:left;"/>
<col style="text-align:left;"/>
</colgroup>

<thead>
<tr>
	<th style="text-align:left;">Type</th>
	<th style="text-align:left;">Description</th>
</tr>
</thead>

<tbody>
<tr>
	<td style="text-align:left;">Firewall (screening router)</td>
	<td style="text-align:left;">1<sup>st</sup> generation packet filter that filters packets between networks. Blocks/accepts traffic based on IP addresses, ports, protocols</td>
</tr>
<tr>
	<td style="text-align:left;">Stateful inspection firewall</td>
	<td style="text-align:left;">2<sup>nd</sup> generation packet filter. Like a screening router but also takes into account TCP connection state and information from previous connections (e.g., related ports for TCP)</td>
</tr>
<tr>
	<td style="text-align:left;">Deep Packet Inspection firewall</td>
	<td style="text-align:left;">3<sup>rd</sup> generation packet filter. Examines application-layer protocols</td>
</tr>
<tr>
	<td style="text-align:left;">Application proxy</td>
	<td style="text-align:left;">Gateway between two networks for a specific application. Prevents direct connections to the application from outside the network. Responsible for validating the protocol</td>
</tr>
<tr>
	<td style="text-align:left;">IDS/IPS</td>
	<td style="text-align:left;">Can usually do what a stateful inspection firewall does + examine application-layer data for protocol attacks or malicious content</td>
</tr>
<tr>
	<td style="text-align:left;">Host-based firewall</td>
	<td style="text-align:left;">Typically screening router with per-application awareness. Sometimes includes anti-virus software for application-layer signature checking</td>
</tr>
<tr>
	<td style="text-align:left;">Host-based IPS</td>
	<td style="text-align:left;">Typically allows real-time blocking of remote hosts performing suspicious operations (port scanning, ssh logins)</td>
</tr>
</tbody>
</table>
<!--
## Snort

Snort is an example of a widely used network intrusion detection system.
Snort sniffs all traffic on the network and
parses each packet to extract fields that can be matched by rules.
A set of rules is then applied to the data extracted from each pocket.
These include tests of the form performed by stateful screening routers on network
and transport layer fields as well as searching for patterns
in the data payload of the packets.
These rules enable one to test for known protocol attacks (e.g., bad URLs, 
root logins) as well as access to services. Violations can be logged or raised as alerts.
-->

<h1 id="websecurity">Web security</h1>

<p>When the web browser was first created, it was relatively simple: it parsed
static content for display and presented it to the user. The content could
contain links to other pages. As such, the browser was not an interesting
security target. Any dynamic modification of pages was done on servers
and all security attacks were focused on those servers. These attacks
included malformed URLs, buffer overflows, root paths, and unicode attacks.</p>

<p>The situation is vastly different now. Browsers have become insanely
complex:</p>

<ul>
<li><p>Built-in JavaScript to execute arbitrary downloaded code</p></li>
<li><p>The Document Object Model (DOM), which allows JavaScript code to change the content and appearance of a web page.</p></li>
<li><p><em>XMLHttpRequest</em>, which enables JavaScript to make HTTP requests back to the server and fetch content asynchronously.</p></li>
<li><p>WebSockets, which provide a more direct link between client and server without the need to send HTTP requests.</p></li>
<li><p>Multimedia support; HTML5 added direct support for <code>&lt;audio&gt;</code>, <code>&lt;video&gt;~</code>, and <code>&lt;track&gt;~</code> tags, as
well as MediaStream recording of both audio and video and even speech recognition and synthesis (with the Chrome browser, for now).</p></li>
<li><p>Access to on-device sensors, including geolocation and tilt</p></li>
<li><p>the NaCl framework on Chrome, providing the Ability to run native apps in a sandbox within the browser</p></li>
</ul>

<p>The model evolved from simple page presentation to that of running an application.
All these features provide a broader attack surface. The fact that many features are relatively new and
more are being developed increases the likelihood of more bugs and therefore more security holes.
Many browser features are complex and developers won&#8217;t always pay attention to every detail of the
specs (see <a href="http://www.quirksmode.org">quirksmode.org</a>). This leads to an environment where certain
less-common uses of a feature may have bugs or security holes on certain browsers.</p>

<h2 id="multiplesources">Multiple sources</h2>

<p>Traditional software is installed as a single application. The application may use external libraries, but
these are linked in by the author and tested. Web apps, on the other hand, dynamically load components
from different places. These include fonts, images, scripts, and video as well as embedded iFrames that
embed HTML documents within each other. The JavaScript code may issue XMLHttpRequests to yet additional
sites.</p>

<p>One security concern is that of software stability. If you import JavaScript from several different
places, will your page still display correctly and work properly in the future as those scripts
are updated and web standards change? Do those scripts attempt to do anything malicious? Might they
be modified by their author to do something malicious in the future?</p>

<p>Then there&#8217;s the question of how elements on a page <em>should</em> be allowed to interact.
Can some analytics code access JavaScript variables that come from a script downloaded from jQuery.com on the same web page?
The scripts came from different places the page author selected them for the page, so maybe it&#8217;s ok for them to interact.
Can analytics scripts interact with event handlers? If the author wanted to measure mouse movements and keystrokes,
perhaps it&#8217;s ok for a downloaded script to use the event handler.
How about embedded frames? To the user, the content within a frame looks like it is part of the rest of
the page. Should scripts work any differently?</p>

<h2 id="framesandiframes">Frames and iFrames</h2>

<p>A browser window may contain a collection of documents from different sources. Each
document is rendered inside a frame. In the most basic case, there is just one frame: the document window.
A <strong>frame</strong> is a rigid division that is part of a frameset, a collection of frames.
Frames are not officially supported in HTML, the latest version of HTML, but many browsers still support them.
An <strong>iFrame</strong> is a floating inline frame that moves with the surrounding content. iFrames
are supported. When we talk about frames, we will be talking about the frames created with an iFrame tag.</p>

<p>Frames are generally invisible to users and are used
to delegate screen area to content from another source.
A very basic goal of browser security is to isolate visits to separate pages in distinct windows or tabs. If
you visit a.com and b.com in two separate tabs, the address bar will identify each of them and they will not
share information. Alternatively, a.com may have frames within it (e.g., to show ads from other sites, so
b.com may be a frame within a.com. Here, too, we would like the browser to provide isolation between a.com
and b.com even though b.com is not visible as a distinct site to the user.</p>

<h2 id="same-originpolicy">Same-origin policy</h2>

<p>The security model used by web browsers is the <strong>same-origin policy</strong>.
A browser permits scripts in one page to access data in a second page
<em>only</em> if both pages have the same origin. An origin
is defined to be the URI scheme (http vs. https), the hostname, and the port.
For example</p>

<pre><code>http://www.poopybrain.com/419/test.html
</code></pre>

<p>and</p>

<pre><code>http://www.poopybrain.com/index.html
</code></pre>

<p>have the same origin since they both use http, both use port 80 (the default
http port since none is specified), and the same hostname (www.poopybrain.com).
If any of those components were different, the origin would not be the same.
For instance, www.poopybrain.com is <em>not</em> the same hostname as poopybrain.com.</p>

<p>Under the same-origin policy, each origin has access to common client-side resources
that include:</p>

<ul>
<li><p><strong>Cookies</strong>: Key-value data that clients or servers can set. Cookies associated with the origin are sent with each http request.</p></li>
<li><p><strong>JavaScript</strong> namespace: Any functions and variables defined or downloaded into a frame share that frame&#8217;s origin.</p></li>
<li><p><strong>DOM tree</strong>: This is the JavaScript definition of the HTML structure of the page.</p></li>
<li><p><strong>DOM storage</strong>: Local key-value storage.</p></li>
</ul>

<p>Each frame gets the origin of its URL. Many pages will have just one frame: the browser window. Other pages may
embed other frames. Each of those embedded frames will not have the origin of the outer frame but rather the
URL of the frame contents. Any JavaScript code downloaded into a frame will execute with the
authority of its frame&#8217;s origin. For instance, if cnn.com loads JavaScript from jQuery.com, the script runs with the authority of cnn.com.
<strong>Passive content</strong>, which is non-executable content such as CSS files and images, has no authority.
This normally should not matter as passive content does not contain executable code
but there have been attacks in the past that had code in passive content and made that passive content turn active.</p>

<h2 id="cross-origincontent">Cross-origin content</h2>

<p>As we saw, it is common for a page to load content from multiple origins. The same-origin policy
states that JavaScript code from anywhere runs with the authority of the frame&#8217;s origin.
Content from other origins is generally not readable or writable by JavaScript.</p>

<p>A frame can load
images from other origins but cannot inspect that image. However, it can infer the size
of the image by examining the changes to surrounding elements after it is rendered.</p>

<p>A frame may embed CSS (cascading stylesheets) from any origin but cannot inspect
the CSS content. However, JavaScript in the frame can discover what the stylesheet does by creating
new DOM nodes (e.g., a heading tag) and see how the styling changes.</p>

<p>A frame can load JavaScript, which executes with the authority of the frame&#8217;s origin.
If the source is downloaded from another origin, it is executable but not readable.
However, one can use JavaScript&#8217;s <code>toString</code> method to decompile the function
and get a string representation of the function&#8217;s declaration.</p>

<p>All these restrictions are somewhat ineffective anyway since a curious user can download
any of that content directly (e.g., via the <code>curl</code> command) and inspect it.</p>

<h2 id="cross-originresourcesharingcors">Cross-Origin Resource Sharing (CORS)</h2>

<p>Even though content may be loaded from different origins, browsers
restrict cross-origin HTTP requests that are initiated from scripts
(e.g., via <em>XMLHttpRequest</em> or <em>Fetch</em>). This can be problematic at times since
sites such as poopybrain.com and www.poopybrain.com are considered
distinct origins, as are http://poopybrain.com and https://poopybrain.com.</p>

<p><strong>Cross-Origin Resource Sharing</strong> (<strong>CORS</strong>) was created to allow web
servers to specify cross-domain access permission. This will allow scripts
on a page to issue HTTP requests to approved sites. It also allows
access to Web Fonts, inspectable images, and access to stylesheets.
CORS is enabled by an HTTP header that states allowable origins. For example,</p>

<pre><code>Access-Control-Allow-Origin: http://www.example.com
</code></pre>

<p>means that the URL http://www.example.com will be treated as the
same origin as the frame&#8217;s URL.</p>

<h2 id="cookies">Cookies</h2>

<p>Cookies are name-value sets that are designed to maintain state between
a web browser and a server. Cookies are sent to the server along with
HTTP requests and servers may send back cookies with a response.
Uses for cookies include storing a session ID that identifies your
browsing session to the server (including a reference to your
shopping cart or partially-completed form), storing shopping cart
contents directly, or tracking which pages you visited on the site in the past (<strong>tracking cookies</strong>).
Cookies are also used to store authentication information so you
can be logged into a page automatically upon visiting it (<strong>authentication cookies</strong>).</p>

<p>Now the question is: which cookies should be sent to a server when a browser
makes an HTTP request?
Cookies don&#8217;t quite use the same concept of an origin.
The scope of a cookie is defined by its <strong>domain</strong> and <strong>path</strong>. Unlike origins, the
scheme (http or https) is ignored by default, as is the port. The path
is the path under the root URL, which is ignored for determining origins but
used with cookies.
Unless otherwise defined by the server, the default domain and path are those
of the frame that made the request. </p>

<p>A client cannot set cookies for a different domain.
A server, however, can specify top-level or deeper domains.
Setting a cookie for a domain example.com will cause that cookie
to be sent whenever example.com or any domain under example.com
is accessed (e.g., www.example.com). For the cookie to be accepted
by the browser, the domain must include the origin domain of the frame.
For example, if you are on the page www.example.com, your browser will
accept a cookie for example.com but will <em>not</em> accept a cookie
for foo.example.com.</p>

<p>Cookies often contain user names, complete authentication information, or shopping cart contents.
If malicious code running on the web page could access those cookies, it could
modify your cart, get your login credentials, or even modify cookies related
to cloud-based services to have your documents or email get stored to a different
account. This is a very real problem and two safeguards were put in place:</p>

<p>A server can tag a cookie with an <strong>HttpOnly</strong> flag. This will not allow scripts
on the page to access the cookie, so it is useful to keep scripts from
modifying or reading user identities or session state.</p>

<p>HTTP messages are sent via TCP. Nothing is encrypted. An attacker that has
access to the data stream (e.g., a man in the middle or a packet sniffer) can freely read
or even modify cookies. A <strong>Secure</strong> flag was added to cookies to specify that
they can be sent <em>only</em> over an HTTPS connection.:</p>

<pre><code>Set-Cookie: username=paul; path=/; HttpOnly; Secure
</code></pre>

<p>If a user is making requests via HTTP, Secure cookies will not be transmitted.</p>

<h2 id="cross-siterequestforgeryxsrf">Cross-Site Request Forgery (XSRF)</h2>

<p><strong>Cross-site request forgery</strong> is an attack that sends unauthorized requests from a user
that the web server trusts. Let&#8217;s consider an example.
You previously logged into Netflix. Because of that, the Netflix server
sent an authentication cookie to your browser; you will not have to log in the time you visit netflix.com.
Now you go to another website that contains a malicious link or JavaScript code to access a URL.
The URL is:</p>

<pre><code>http://www.netflix.com/JSON/AddToQueue?movieid=860103
</code></pre>

<p>By hitting this link on this other website, the attacker added
<a href="https://en.wikipedia.org/wiki/Plan_9_from_Outer_Space">Plan 9 from Outer Space</a> to
your movie queue (this attack really worked with Netflix but has been fixed).
This may be a minor annoyance but the same attack could create more
malicious outcomes. If, instead of Netflix, the attack could take place against an e-commerce
site that accepted your credentials but allows the attacker to add a different shipping
address on the URL. More dangerously, a banking site may use your stored credentials and account number.
Going to the malicious website may enable the attacker to request a funds transfer to another account:</p>

<pre><code>http://www.bank.com/action=transfer*amount=1000000&amp;to_account=417824919
</code></pre>

<p>Note that the attack works because of how cookies work. You visited a random
website but inadvertently requested another site. Your browser dutifully sends and HTTP GET
request to that site with the URL specified in the link and also sends all the cookies
for that site. The attacker never steals your cookies and does not intercept any traffic.
The attack is simply the creation of a URL that makes it look like you requested some action.</p>

<p>There are several defenses against Cross-site request forgery:</p>

<ul>
<li><p>The server can validate the <code>Referer</code> header on the request. This will tell it whether the request
came via a link or directly from a user (or from a link on a trusted site).</p></li>
<li><p>The server can require some unique token to be present in the request. For instance, visiting
netflix.com might cause the Netflix server to return a token that will need to be passed to
any successive URL. An attacker will not be able to create a static URL on her site that
will contain this random token.</p></li>
<li><p>The interaction with the server can use HTTP POST requests instead GET requests, placing
all parameters into the body of the request rather than in the URL. State information can
be passed via hidden input fields instead of cookies.</p></li>
</ul>

<h2 id="clickjacking">Clickjacking</h2>

<p><strong>Clickjacking</strong> is a deception attack where the attacker overlays an image to have the user think
that he is clicking some legitimate link or image but is really requesting something else.
For example, a site may present a &#8220;win a free iPad&#8221; image. However, malicious JavaScript in the page
can place an <strong>invisible frame</strong> over this image that contains a link. Nothing is displayed
to obstruct the &#8220;win a free iPad&#8221; image but when a user clicks on it, the link that
is processed is the one in the invisible frame. This malicious link could download malware,
change security settings for the Flash plug-in, or redirect the user to a page containing
malware or a phishing attack.</p>

<p>A defense for clickjacking is to use defensive JavaScript in the legitimate code to check that
the content is at the topmost layer:</p>

<pre><code>window.self == window.top
</code></pre>

<p>If it isn&#8217;t then it means the content is obstructed, possibly by an invisible clickjacking
attack. Another defense is to have the server send an X-Frame-Options HTTP header
to instruct the browser to not allow framing from other domains.</p>

<h2 id="screensharing">Screen sharing</h2>

<p>HTML5, the latest standard for HTML, added a screen-sharing API.
Normally, no cross-origin communication is permitted between client and server.
The screen-sharing API violates this. If a user grants screen-sharing permission to a
frame, the frame can take a screenshot of the entire display (the entire monitor, all windows, and the browser).
It can also get screenshots of pages hidden by tabs in a browser.</p>

<p>This is not a security hole and there are no exploits (yet) to enable screen sharing
without the user&#8217;s explicit opt-in. However, it is a risk because the user might not be
aware of the scope or duration of screen sharing. If you believe that you are sharing one
browser window, you may be surprised to discover that the server was examining all your
screen content.</p>

<h2 id="inputsanitization">Input sanitization</h2>

<p>In the past we saw how user input that becomes a part of database queries or commands can
alter those commands and, in many cases, enable an attacker to add arbitrary queries or commands.
The same applies to URLs, HTML source, and JavaScript. Any user input needs to be
parsed carefully before it can be made part of a URL, HTML content, or JavaScript.
Consider a script that is generated with some in-line data that came from a malicious user:</p>

<pre><code>&lt;script&gt; var x = &quot;untrusted_data&quot;; &lt;/script&gt;
</code></pre>

<p>The malicious user might define that untrusted_data to be</p>

<pre><code>Hi&quot;; &lt;/script&gt; &lt;h1&gt; Hey, some text! &lt;/h1&gt; &lt;script&gt; malicious code... x=&quot;bye
</code></pre>

<p>The resulting script to set the variable <code>x</code> now becomes</p>

<pre><code>&lt;script&gt; var x = &quot;Hi&quot;; &lt;/script&gt; &lt;h1&gt; Hey, some text! &lt;/h1&gt; &lt;script&gt; malicious code... x=bye&quot;; &lt;/script&gt;
</code></pre>

<h2 id="cross-sitescripting">Cross-site scripting</h2>

<p><strong>Cross-site Scripting</strong> (<strong>XSS</strong>) is a code injection attack that allows
the attacker to inject client-side scripts into web pages. It can be used to bypass
the same-origin policy and other access controls. Cross-site scripting has been one
of the most popular browser attacks.</p>

<p>The attack may be carried out in two ways: a URL that a user clicks on and gets back
a page with the malicious code and by going to a page that contains user content that
may include scripts.</p>

<p>In a <strong>Reflected XSS</strong> attack, all malicious content is in a page request, typically
a link that an unsuspecting user will click on.
The server will accept the request without sanitizing the user input and present
a page in response. This page will include that original content. A common example
is a search page that will display the search string before presenting the
results (or a &#8220;not found&#8221; message). Another example is an invalid login request that
will return with the name of the user and a &#8220;not found&#8221; message.
Consider a case where the search string or the login name is not just a bunch
of characters but text to a script. The server treats it as a string, does the
query, cannot find the result, and sends back a page that contains that string,
which is now processed as inline JavaScript code.</p>

<pre><code>www.mysite.com/login.asp?user=&lt;script&gt;malicious_code(…) &lt;/script&gt;
</code></pre>

<p>In a <strong>Persistent XSS</strong> attack, user input is stored at a site and later presented
to other users. Consider online forums or comment sections for news postings and blogs.
If you enter inline JavaScript as a comment, it will be placed into the page that
the server constructs for any future people who view the article. The victim will not
even have to click a link to run the malicious payload.</p>

<p>Cross-site scripting is a problem of <strong>input sanitization</strong>.
Servers will need to parse input that is expected to be a string to ensure that
it does not contain embedded HTML or JavaScript. The problem is more difficult
with HTML because of its support for encoded characters. A parser will
need to check not only for &#8220;<code>script</code>&#8221; but also for &#8220;<code>%3cscript%3e</code>&#8221;.
As we saw earlier, there may be several acceptable Unicode encodings for the
same character.</p>

<p>Cross-site scripting, by executing arbitrary JavaScript code can:</p>

<ul>
<li>Access cookies related to that website</li>
<li>Hijack a session</li>
<li>Create arbitrary HTTP requests with arbitrary content via <em>XMLHtttpRequest</em></li>
<li>Make arbitrary modifications to the HTML document by modifying the DOM</li>
<li>Install keyloggers</li>
<li>Download malware &#8211; or run JavaScript ransomware</li>
<li>Try phishing by manipulating the DOM and adding a fake login page</li>
</ul>

<p>The main defense against cross-site scripting is to sanitize all input.
Some web frameworks do this automatically. For instance,
<a href="https://www.djangoproject.com">Django</a> templates allow the author
to specify where generated-content is inserted (e.g., <code>&lt;b&gt; hello, {{name}} &lt;/b&gt;</code>)
and performs the
necessary sanitization to ensure it does not modify the HTML or add JavaScript.</p>

<p>Other defenses are:</p>

<ul>
<li><p>Use a less-expressive markup language for user input, such as <em>markdown</em> if
you want to give users the ability to enter rich text. However, input sanitization
is still needed to ensure there are no HTML or JavaScript escapes</p></li>
<li><p>Employ a form of <strong>privilege separation</strong> by placing untrusted
content inside a frame with a different origin. For example,
user comments may be placed in a separate domain. This does not
stop XSS damage but limits it to the domain.</p></li>
<li><p>Use the <strong>Content Security Policy</strong> (<strong>CSP</strong>). The
<a href="https://developers.google.com/web/fundamentals/security/csp/">content security policy</a>
was designed to defend agains XSS and clickjacking attacks.
It allows website owners to tell clients
what content is allowed, whether inline code is permitted, and
whether the origin should be redefined to be unique.</p></li>
</ul>

<h2 id="sqlinjection">SQL injection</h2>

<p>We previously saw that SQL injection is an issue in any software that uses user input as part of the
the SQL query. The same applies to browsers. Many web services have databases behind them
and links often contain queries mixed with user input. If input is not properly sanitized,
it can alter the SQL query to modify the database, force a user authentication, or return
the wrong data.</p>

<h2 id="gifarattack">GIFAR attack</h2>

<p>The GIFAR attack is a way to embed malicious code into an image file.
Sites that allow user-uploadable pictures are vulnerable.
GIFAR is a pseudo-concatenation of GIF and JAR.</p>

<p>Java applets are sent as JAR files. A Java JAR file is essentially a zip file, a popular
format for compressing and archiving multiple files. In Jar files, the header that contains
information about the content is stored at the <em>end</em> of the file.</p>

<p>GIF files are lossless image files. The header in GIF files, as with most other file formats,
is stored at the <em>beginning</em> of the file.</p>

<p>GIF and JAR files can be combined together to create a GIFAR file. Because the GIF header
is at the beginning of the file, the browser believes it is an image and opens it as such,
trusts its content, unaware that it contains code. Meanwhile the Java virtual machine (JVM)
recognizes the JAR part of the file, which is run as an applet in the victim&#8217;s browser.</p>

<p>An attacker can use cross-site scripting to inject a request to invoke the applet
(<code>&lt;applet archive:&quot;myimage.gif&quot;&gt;</code>), which will cause it to run in the context
of the origin (the server that hosted it). Because the code is run as a Java applet rather
than JavaScript,
it bypasses the &#8220;no authority&#8221; restriction the browser imposes on JavaScript in images.</p>

<h2 id="htmlimagetagvulnerability">HTML image tag vulnerability</h2>

<p>We saw that the same-origin policy treats images as static content with no authority.
It would seem that images should not cause problems (ignoring the now-patched
GIFAR vulnerability that allowed images to inject Java applets). However,
an image tag (<code>IMG</code>) can pass parameters to the server, just like any other URL:</p>

<pre><code>&lt;img src=&quot;http://evil.com/images/balloons.jpg?extra_information&quot; height=&quot;300&quot; width=&quot;400&quot;/&gt;
</code></pre>

<p>This can be used to notify the server that the image was requested from specific content.
The web server will also know the IP address that sent the request. The image itself can
be practically hidden by setting its size to a single pixel:</p>

<pre><code>&lt;img src=&quot;...&quot; height=&quot;1&quot; width=&quot;1&quot; /&gt;
</code></pre>

<p>This is sometimes done to track messages sent to user. If I send you HTML-formatted mail
that contains a one-pixel image, you will not notice the image but my server will be
notified that the image was downloaded. If the <code>IMG</code> tag contained some text
to identify that this is related to the mail message I sent you, I will now know
that you read the message.</p>

<p>Images can also be used for social engineering: to disguise a site by appropriating
logos from well-known brands or adding certification logos.</p>

<h2 id="mixedhttpandhttpscontent">Mixed HTTP and HTTPS content</h2>

<p>A web page that was served via HTTPS might contain a reference to a URL, such
as a script, that specifies HTTP content:</p>

<pre><code>&lt;script src=&quot;http://www.mysite.com/script.js&quot;&gt; &lt;/script&gt;
</code></pre>

<p>The browser would follow the scheme in the URL and download that content
via HTTP rather than over the secure link. An active network attacker can hijack
that session and modify the content. A safer approach is to not specify the
scheme for scripts, which would cause them to be served over the same protocol
as their embedding frame.</p>

<pre><code>&lt;script src=&quot;//www.mysite.com/script.js&quot;&gt; &lt;/script&gt;
</code></pre>

<p>Some browsers give warning of mixed content but the risks and knowledge of what really is
going on might not be clear to users.</p>

<h2 id="extendedvalidationcertificates">Extended Validation Certificates</h2>

<p>TLS establishes a secure communication link between a client and server.
For the authentication to be meaningful, the user must be convinced that
the server&#8217;s X.509 certificate truly belongs to the entity that is identified
in the certificate. Would you trust a bankofamerica.com certificate issued
the Rubber Ducky Cert Shack? Even legitimate issuers such as Symantec offer
varying levels of validating a certificate owner&#8217;s identity.</p>

<p>The lowest level of identity assurance for organizations
is a <strong>domain validated</strong> certificate. To validate the user,
the certificate authority will validate that some contact at that
domain approves the request. This is usually done through email.
It does not prove that the user has legal authority to act on
behalf of the company nor is there any validation of the company.
They require consent of the domain owner but do not try to validate who that owner is.
They offer only incrementally more
identity binding than <strong>self-signed certificates</strong>.</p>

<p>With <strong>extended validation</strong> (<strong>EV</strong>) certificates, the certificate
authority uses a more rigorous, human-driven validation process.
The legal and physical presence of the organization is validated.
Then, the organization is contacted through a verified phone number and both
the contact and the contact&#8217;s supervisor must confirm the
authenticity of the request.</p>

<p>An extended validation certificate contains the usual data in a
certificate (public key, issuer, organization, &#8230;) but must
also contain a government-registered serial number and a physical address
of the organization.</p>

<figure>
<img src="images/cert-rutgers.png" alt="Domain validated certificate" id="domainvalidatedcertificate" title="Domain Validated Certificate" style="height:25px;width:182;" />
<figcaption>Domain validated certificate</figcaption></figure>



<figure>
<img src="images/cert-jpm.png" alt="Extended validation certificate" id="extendedvalidationcertificate" title="Extended Validation Certificate" style="height:25px;width:319;" />
<figcaption>Extended validation certificate</figcaption></figure>




<p>An attacker could get a low-level certificate and set up a web site.
Targets would go to it, see the lock icon on their browser&#8217;s address bar
that indicates an SSL connection, and feel secure. This led users to a false
sense of security: the connection is encrypted but there is no reason
to believe that there is validity to the organization on the other side.</p>

<p>Modern browsers identify and validate EV certificates. Once validated,
the browser presents an enhanced security indicator that identifies
the certificate owner.</p>

<h2 id="browserstatusbar">Browser status bar</h2>

<p>Most browsers offer an option to display a status bar that shows the URL of a link before you click it.
This bar is trivial to spoof by adding an onclick attribute to the link that invokes JavaScript
to take the page to a different link. In this example, hovering over the PayPal link will show a
link to <code>http://www.paypal.com/signin</code>, which appears to be a legitimate PayPal login page.
Clicking on that link, however, will take the user to <code>http://www.evil.com</code>.</p>

<pre><code>&lt;a href=&quot;http://www.paypal.com/signin&quot;
    onclick=&quot;this.href = 'http://www.evil.com/';&quot;&gt;PayPal&lt;/a&gt;
</code></pre>

<h1 id="mobiledevicesecurity">Mobile device security</h1>

<h2 id="whatmakesmobiledevicesunique">What makes mobile devices unique?</h2>

<p>In many ways, mobile devices should not be different from laptops
or other computer systems. They run operating systems that are
derived from those those systems, run multiple apps, and connect
to the network. There are differences, however, that make them more attractive targets to attackers. </p>

<h3 id="users">Users</h3>

<p>Several user factors make phones different from most computing devices:</p>

<ul>
<li><p>Mobile users often do not think of their phones as real computers. They
may not have the same level of paranoia that malware may get in or
their activities may be monitored.</p></li>
<li><p>Users tend to install a lot more apps on their phones than they do on their computers.
These apps are more likely to be from unknown software vendors than those installed on computers.</p></li>
<li><p>Social engineering may work more easily on phones. People
are often in distracted environments when using their phones
and may not pay attention to realize they are experiencing a phishing attack.</p></li>
<li><p>Phones are small. Users may be less likely to notice some security indicators,
such as an EV certificate indicator. It is also easier to lose the phone &#8230; or
have it stolen.</p></li>
<li><p>A lot of phones are protected with bad PINs. Four-digit PINs still dominate
and, as with passwords, people tend to pick bad ones &#8211; or at least common ones.
In fact, four PINs (1234, 1111, 0000, 1212, 7777) account for
<a href="http://www.datagenetics.com/blog/september32012/">over 20% of PINs</a> chosen by users.</p></li>
<li><p>While phones have safeguards to protect resources that apps can access users
may grant app permission requests without thinking: they will just click through
during installation to get the app up and running.</p></li>
</ul>

<h3 id="interfaces">Interfaces</h3>

<p>Phones have many sensors built into them:
GSM, Wi-Fi, Bluetooth, and NFC radios as well as a GPS, microphone,
camera. 6-axis gyroscope and accelerometer, and even barometer.
These sensors can enable attackers to monitor the world around you:
identify where you are and whether you are moving. They can record
conversations and even capture video.
The sensors are so sensitive that it has been demonstrated that a phone
on a desk next to a keyboard can pick up vibrations from a user
typing on the neighboring keyboard. This led to a word recovery rate of 80%.</p>

<h3 id="apps">Apps</h3>

<p>There are a lot of mobile apps. Currently, there are about
2.6 million Android apps and 2.2 million iOS apps.
Most of these apps are written by unknown, and hence untrusted, parties.
We would be be wary of downloading many of these on our PCs but
think nothing of doing so on our phones.
We place our trust in several areas:</p>

<ul>
<li>The testing &amp; approval process by Google (automated) and Apple (automated + manual)</li>
<li>The ability of the operating system to sandbox an application</li>
<li>The operating system&#8217;s requirement of users granting permissions to access certain resources.</li>
</ul>

<p>This trust may be misplaced as the approval process is far from foolproof.
Overtly misadvertised or malicious apps can be detected but it is impossible to discern what a program will do in the future. Sandboxes have been broken in the past and users may be too happy to grant permissions to apps. Moreover, apps often ask for more permissions than they use. For example, a security researcher surveyed flashlight apps available for Android and <a href="https://www.zdnet.com/article/most-android-flashlight-apps-request-an-absurd-number-of-permissions/">discovered</a> that, of the 937 apps surveyed, the majority requested an average of 25 permissions per app.</p>

<p>Most apps do not get security updates. There is little economic incentive for a developer to support existing apps, particularly if newer ones have been deployed.</p>

<h3 id="platform">Platform</h3>

<p>Mobile phones are comparable to desktop systems in complexity. In some cases, they may even be more complex. This points to the fact that, like all large systems, they will have bugs and some of these bugs will be security
sensitive. For instance, in late March, 2017, Apple released an upgrade for iOS, stating that they fixed over 80 security flaws. This is almost 10 years after the release of the iPhone. You can be certain there are many more flaws lurking in the system and more will be added as new features are introduced.</p>

<p>Because of bugs in the system, malicious apps may be able to get root privileges. If they do, they can install rootkits, enabling long-term control while concealing their presence. A lot of malicious iOS apps, for instance, gained root privileges by exploiting heap overflow vulnerabilities. </p>

<p>Unlike desktop systems and laptops, phones enforce a single user environment. Although PCs are usually used as single-user systems, they support multiple user accounts and run a general-purpose timesharing operating system. Mobile devices are more carefully tuned to the single-user environment.</p>

<h3 id="threats">Threats</h3>

<p>Mobile devices are are threats to personal privacy as well as at risk of traditional
security violations. Personal privacy threats include identifying users and user
location, accessing the camera and microphone, and leaking personal data from the
phone over the network. Additional threats include traditional phishing attacks,
malware installation, malicious Android intents (messages to other apps or services),
and overly-broad access to system resources and sensors.</p>

<h2 id="androidsecurity">Android security</h2>

<p>Android was conceived as an operating system for network-connected smart mobile devices. The company was acquired by Google in 2005 and the engineering effort shifted to developing it as a Linux-based operating system platform that would be provided for free to third-party phone manufacturers. Google would make money from services and apps.</p>

<p>Applications on Android had specific needs, some of which have not been priorities in the design of desktop operating systems. These include:</p>
<dl>
<dt>Integrity</dt>
<dd>The platform should ensure that the app is not modified between the time of its creation and its installation by users.</dd>

<dt>Isolation</dt>
<dd>Each app needs private data and app components as well as the private data need to be protected from other apps.</dd>

<dt>Sharing</dt>
<dd>Apps may need access to shared storage and devices, including the network. This includes the on-device file system, external storage, communication interfaces, and the various sensors available on phones and other smart devices.</dd>

<dt>Inter-app services</dt>
<dd>An app needs to be able to send messages to other apps to interact with services – but only when it is permitted to do so. This affects the design of apps. Desktop apps have a single launching point and generally run as single, monolithic process. Android apps, on the other hand, contain multiple independent components that include activities (user-facing parts), services (background components), and content providers (data access components).</dd>

<dt>Portability</dt>
<dd>The previous needs are general and apply to other mobile platforms, such as iOS. Since Android was designed as an operating system for a variety of hardware, apps should be able to run on different hardware architectures. A decision was made that apps should be distributed in a portable, architecture-neutral format. Apps run under the ART (Android Runtime) virtual machine, which is a variant of of the Java virtual machine (JVM).
The original intention in Android was that apps would be written only in
Java but it soon became clear that support for native (C and C++) code was
needed and Google introduced the Native Development Kit to support this.</dd>
</dl>


<h3 id="apppackage">App package</h3>

<p>An Android app is distributed as a package in an APK format, which is a single zip-format compressed file that contains several components:</p>
<dl>
<dt>Activity</dt>
<dd>Code for the user-visible component - the interface. The code component includes compiled code and needed resource files, such as strings, images, UI layouts, and data.</dd>

<dt>Service</dt>
<dd>Code background component - services that the app may offer to other programs</dd>

<dt>Content provider</dt>
<dd>A database for whatever persistent data the app needs to store. It implements APIs to provide access to structured data. For instance, user contacts will be stored in a content provider.</dd>

<dt>Broadcast receiver</dt>
<dd>Mailbox for received messages</dd>

<dt><strong>Package manifest</strong> (META-INF)</dt>
<dd>This contains items needed to validate the origin of the package and that it has not been tampered:
 - Signed list of hashes
 - Application creator’s certificate</dd>

<dt><strong>Application manifest</strong></dt>
<dd>This enumerates what makes up the application and includes:
 - Name (e.g., com.example.myapp)
 - Components list
 - Device requirements
 - Intents: interfaces the app supports to activate services &amp; activities
 - Permissions: access to services this app requires (e.g., android.permission.SEND_SMS)
 - Permissions other apps need to access services this app provides</dd>
</dl>


<h3 id="appintegrity">App Integrity</h3>

<p>All Android apps must be signed by the developer. This allows both developers and users to know that the application will be installed without modifications on their device. On installation, the Android Package Manager verifies the signature. </p>

<p>Applications do not have to be signed by any central authorities. Developers can use a self-signed certificate and Android does not perform verification of CAs (certification authorities) in the certificate. </p>

<p>Prior to distribution, the contents of the APK package are hashed and signed by the developer and then the signature along with the developer&#8217;s certificate is inserted into the APK.</p>

<p>The app package is verified prior to installation by creating a hash and validating it against the signature in the package. If the app is distributed through the Google Play store, Google performs the same checks.</p>

<p>For additional protection, Google optionally supports a feature called <strong>Google Play Protect</strong>. This validates the app before it is downloaded and checks the user&#8217;s device for potential malware. It warns the user about malware or any apps that violate Google&#8217;s <em>Unwanted Software Policy</em>, such as apps that hide or misrepresent information.</p>

<h3 id="theandroidappsandbox">The Android app sandbox</h3>

<p>Android relies on <strong>process sandboxing</strong> for most of its security. Android is based on Linux, which is a multi-user operating system. Under Linux, each user has a distinct user ID and all apps run by that user run with the privileges of the user (ignoring setUID apps). This allows any one app full access to all user data. </p>

<h4 id="userids">User IDs</h4>

<p>Android supports only a single user and uses Linux user IDs for isolating app privileges. Under Android, each app normally runs under a different user ID. Hence, apps are isolated and can only access their resources. Access requests to other objects involve messages that pass through a <strong>gatekeeper</strong>, which validates access requests.</p>

<p>Core Android services also run in a similar manner, with each service running under its own unique user ID. For example:</p>

<table>
<colgroup>
<col style="text-align:left;"/>
<col style="text-align:left;"/>
</colgroup>

<thead>
<tr>
	<th style="text-align:left;">user id</th>
	<th style="text-align:left;">service</th>
</tr>
</thead>

<tbody>
<tr>
	<td style="text-align:left;">1001</td>
	<td style="text-align:left;">Telephony</td>
</tr>
<tr>
	<td style="text-align:left;">1002</td>
	<td style="text-align:left;">Bluetooth</td>
</tr>
<tr>
	<td style="text-align:left;">1003</td>
	<td style="text-align:left;">Graphics</td>
</tr>
<tr>
	<td style="text-align:left;">1004</td>
	<td style="text-align:left;">Input devices</td>
</tr>
<tr>
	<td style="text-align:left;">1005</td>
	<td style="text-align:left;">Audio</td>
</tr>
</tbody>
</table>
<p>Related apps may share the same Linux user ID if a <code>sharedUserID</code> attribute is set to the same domain for two or more applications as long as those
apps are also signed by the same certificate. This would allow these related apps to share files and they can be configured to even share the same Dalvik virtual machine.</p>

<h4 id="filepermissions">File permissions</h4>

<p>Two mechanisms are used to enforce file access permissions:</p>

<ol>
<li><p>Linux file permissions
These provide discretionary access control, allowing the owner (and root) to change permissions to allow others access to the files. With this mechanism, an app can decide to share a data file.</p></li>
<li><p>SELinux mandatory access control
Certain data and cache directories in Android are protected with the SELinux (Security-Enhanced Linux) mandatory access control (MAC) kernel extension. This ensures that even the owner cannot change access permissions for the files.</p></li>
</ol>

<p>Internal storage provides a per-app private directory for files used by each application. External storage (e.g., attached microSD cards or USB devices) is shared among all apps and, of course, may be moved to other computers.</p>

<h3 id="intents">Intents</h3>

<p>Android apps communicate with system services, between app components, and with other apps via <em>intents</em>. <strong>Intents</strong> are messaging objects. An intent is a message that contains:
 - requested action
 - data being sent to the action
 - the component and app that should handle the intent</p>

<p>Intents are declarations of app capabilities and the messaging format used to communicate with an app. They identify app components and how those components are started (e.g., foreground or background and what the entry points are). </p>

<p>Intents allow an app to:</p>

<ul>
<li>Start a service (background task)</li>
<li>Start an activity (start a user-facing foreground task, such as a camera or phone)</li>
<li>Deliver notifications to one or more apps (broadcasts)</li>
</ul>

<p>An app lists its available intents in its app manifest and these intents are registered when the app is installed. The intents form the list of services that the app exposes to other applications. If several apps register the same intent, the user selects which app should be launched. For example, you may have multiple browsers installed and are asked to pick the one that should be associated with implicit intents to display a URL.</p>

<p>Intents may explicit or implicit. With <strong>explicit intents</strong>, the app identifies the target component in the intent. That is, the intent is sent to a specific, named app. With <strong>implicit intents</strong>, the app asks Android to find a component based on the type of data being sent. For example, sending a URL to display a web page can be an explicit intent that will cause Android to open the default web browser.</p>

<p>Intents are used to invoke system services as well as services available on any installed apps.
Common examples of intents are: <em>add a calendar event, set an alarm, take a photo &amp; return it, view a contact, add a contact, show a location on a map, retrieve a file, or initiate a phone call</em>.</p>

<p>Intents pass through &amp; are validated by Android’s gatekeeper. </p>

<h3 id="permissions">Permissions</h3>

<p>An app manifest also contains <strong>permissions</strong>, which can specify which apps or services are allowed access to the app&#8217;s services and whether a user needs to be prompted to grant permission. Permissions determine whether one app is allowed to access another app’s component.</p>

<p>Apps need permissions to access any services, which include:</p>

<ul>
<li>System resources: logs, battery levels, &#8230;</li>
<li>System interfaces: Internet, Bluetooth, send SMS, send email, &#8230;</li>
<li>Sensitive data: SMS messages, contacts, email, &#8230;</li>
<li>Any app-defined services</li>
</ul>

<p>Every service, whether a normal app or a system service is assigned a protection level that determines who may be able to access it:</p>

<table>
<colgroup>
<col style="text-align:left;"/>
<col style="text-align:left;"/>
</colgroup>

<thead>
<tr>
	<th style="text-align:left;">Permission</th>
	<th style="text-align:left;">Type</th>
</tr>
</thead>

<tbody>
<tr>
	<td style="text-align:left;"><em>Normal</em></td>
	<td style="text-align:left;">this is the default; there is no danger to the users or system if this service is accessed</td>
</tr>
<tr>
	<td style="text-align:left;"><em>Dangerous</em></td>
	<td style="text-align:left;">Access can compromise the system or privacy. The user has to approve access during installation or runtime</td>
</tr>
<tr>
	<td style="text-align:left;"><em>Signature</em></td>
	<td style="text-align:left;">Access granted only if the app signed by the same developer &amp; contains the same certificate. This allows related apps to share services (e.g., Microsoft Office apps)</td>
</tr>
<tr>
	<td style="text-align:left;"><em>SignatureOrSystem</em></td>
	<td style="text-align:left;">Similar to <em>signature</em>_ but access will be granted if a system application is requesting it</td>
</tr>
</tbody>
</table>
<p>The application manifest file defines the type of permission and the service that is associated with permission name.</p>

<p>Permissions are managed in two forms:</p>
<dl>
<dt>Permission text strings</dt>
<dd>These are enforced by Android middleware. Sensitive resources such as the phone are only accessible via APIs and access is mediated through these APIs.</dd>

<dt>Linux group IDs</dt>
<dd>Group permissions are enforced by Linux file access checks. For efficiency, networking and file access operations do not go through APIs but directly to Linux. This includes access to Bluetooth, Wi-Fi, and external storage. To be able to access resources, the app needs to be a member of the group that corresponds to the resource. Android dynamically adds user IDs to various groups based on what permissions are granted to them.</dd>
</dl>


<h3 id="otherprotections">Other protections</h3>

<p>The Linux operating system provides per-process memory isolation and address space layout randomization (ASLR). Linux also uses <em>no-execute</em> (NX) protection on stack and heap memory pages if the processor supports it</p>

<p>The Java compiler provides provides stack canaries, and its memory management libraries
provide some heap overflow protections (checks of backward &amp; forward pointers in dynamically allocated structures).</p>

<p>Android supports whole disk encryption so that if a device is stolen, an attacker will not be able to easily recover file contents even with raw access to the flash file system.</p>

<p>Unlike iOS, Android supports the concurrent execution of multiple apps. It is up to the developer to think about being frugal with battery life. Apps store state their state in persistent memory so they can be stopped and restarted at any time. This ability to stop an app also helps with DoS attacks as the app is not accepting requests or using system resources.</p>

<h3 id="securityconcerns">Security concerns</h3>

<p>An app can <strong>probe</strong> whether another app has specific permissions by specifying a permission with an intent method call to that app. This can help an attacker identify a target app. Receivers need to be able to handle <strong>malicious intents</strong>, even for actions they do not expect to handle and for data that might not make sense for the action.</p>

<p>Apps may also exploit <strong>permissions re-delegation</strong>.
An app, not having a certain permission, may be able gain those privileges by communicating through another app.
If a public component does not <em>explicitly</em> have an access permission listed in its manifest definition, Android permits any app to access it.
For example, the
Power Control Widget (a default Android widget) allows third-party apps to change protected system settings without requesting permissions
to control those settings. This is done by presenting the user with a pop-up interface to control power-related settings.
A malicious app can send a fake intent to the Power Control Widget while simulating the pressure of the widget button to switch power-related settings.
It is effectively simulating a user&#8217;s actions on the screen.</p>

<p>By using external storage, apps can exercise <strong>permissions avoidance</strong>.
By default, all apps have access to external storage.
Many apps store data in external storage without specifying any protection,
allowing other apps to access that data.</p>

<p>Another way permissions avoidance is used is that Android intents allow opening some system apps without requiring permission to do so. These
apps include the camera, SMS, contact list, and browser.
For instance, opening a browser via an intent can be dangerous since it enables data transmission, receiving remote commands, and even downloading files without
user intervention.</p>

<h2 id="iossecurity">iOS security</h2>

<h3 id="appsigning">App signing</h3>

<p>iOS requires mandatory code signing. Unlike Android, which accepts self-signed certificates, the app package
must be signed using an Apple Developer certificate and apps are only available for This does not ensure trustworthiness of an app but identifies the registered developer
and ensures that the app has not been modified after it has been signed.</p>

<h3 id="runtimeprotection">Runtime protection</h3>

<p>Apple&#8217;s iOS provides runtime protection via <strong>OS-level sandboxing</strong>.
System resources and the kernel are shielded from user apps.
The sandbox also limits which system calls an app can call
Except through kernel exploits, an app cannot leave its sandbox.</p>

<p>The app sandbox restricts the ability of one app to access another app&#8217;s data and resources. Each app has its own sandbox directory. The OS enforces the sandbox and permits access only to files within that directory, as well as restricted access to
to system preferences, the network, and other resources.</p>

<p>Inter-app communication can take place only through iOS APIs.
Code generation by an app is prevented because data memory pages cannot be made executable
and executable memory pages are not writable by user processes.</p>

<h3 id="dataprotection">Data protection</h3>

<p>All file contents are encrypted with a unique 256-bit AES per-file key, which is generated when the file is created.</p>

<p>This per-file key is encrypted with a class key and is stored along with the file&#8217;s metadata, which is the part of the file system that describes attributes of the file, such as size, modification time, and access permissions.</p>

<p>The class key is generated from
a hardware key in the device and the user&#8217;s passcode. Unless the passcode is entered,
the class key cannot be created and the file key cannot be decrypted.</p>

<p>The file system&#8217;s metadata is also encrypted. A file system key is used
for this, which is derived directly from the hardware key, which is generated when iOS is installed. Keys are stored in Apple&#8217;s Secure Enclave, a separate processor and isolated memory that cannot be accessed directly by the main processor. Encrypting metadata encrypts the entire structure of the file system. Someone who rips out the flash memory from an iOS device and examines it will not be able to see neither file contents (they are encrypted with per-file keys) nor information about those files (the metadata is encrypted with a file system key).</p>

<p>A hardware AES engine encrypts and decrypts the file as it is written/read on flash memory so file encryption is done transparently and efficiently.</p>

<p>The iOS kernel partition is mounted read-only, so even if an app manages to break out of its sandbox due to some vulnerability and gain root access, it will still not have permission to modify the kernel.</p>

<h3 id="communication">Communication</h3>

<p>The iOS sandbox restricts apps from accessing files stored by other apps or making changes to device settings. Each app is given a unique home directory for its files.
System files and resources are shielded from the user’s apps</p>

<p>Unlike Android, where each app is assigned a unique user ID, apps under iOS run as a non-privileged user &#8220;mobile.&#8221;</p>

<p>The iOS framework grants <strong>entitlements</strong> to apps. These are digitally-signed key-value pairs that are granted to an app to allow access to specific services. It is essentially a capability. If you have an entitlement, then you can access a service.</p>

<h3 id="kernelprotection">Kernel protection</h3>

<p>In addition to the sandbox, iOS also uses address space layout randomization (ASLR) and memory execute protection for stack and heap pages via ARM&#8217;s <em>Execute Never</em> (XN) memory page flag.</p>

<h3 id="masqueattacks">Masque attacks</h3>

<p>While Apple normally expects users to install apps only from its App Store, users
need to be able to deploy pre-production apps to friendly parties for testing and
enterprises may need to deploy in-house apps to their employees. Apple supports a
Developer Enterprise Program to create and distribute such in-house apps. This
mechanism has been used to replace existing apps with private versions. The
vulnerability has been patched.</p>

<p>iOS has been hit several times with <strong>masque attacks</strong>. While there have been various
forms of these, the basic attack is to get users to install malicious apps that have been
created with the same <em>bundle identifier</em> as some exiting legitimate app. This
malicious app replaces the legitimate app and masquerades as that app.
Since Apple will not host an app with a duplicate bundle identifier, the
installation of these apps has to bypass the App Store. Enterprise provisioning
is used to get users to install this. which typically requires the user going
to a URL that redirects the user to an XML manifest file hosted on a server.
The ability to launch this attack is somewhat limited as
the user will generally need to have an enterprise certificate installed
to make the installation seamless.</p>

<h2 id="webapps">Web apps</h2>

<p>Both iOS and Android have full web browsers that can be used to access web
applications. They also permit web apps to appear as a regular app icon.
The risks here are the same as those for web browsers in general: loading
untrusted content and leaking cookies and URLs to foreign apps.</p>

<p>Mobile-focused web-based attacks can take advantage of the sensors on phones.
The HTML5 Geolocation API allows JavaScript to find your location. A
<em>Use Current Location</em> permission dialog appears, so the attacker has
to hope the user will approve but there the attacker can provide incentives
via a Trojan horse approach: provide a service that may legitimately need
your location. </p>

<p>Recently, a proof of concept web attack showed how JavaScript could access
the phone&#8217;s accelerometers to detect movements of the phone as a user
enters a PIN. The team that implemented this achieved a 100% success
rate of recognizing a four-digit PIN within five attempts of a user entering it.
Apple patched this specific vulnerability but there may be more undiscovered ones.</p>

<h2 id="hardwaresupportforsecurity">Hardware support for security</h2>

<figure>
<img src="images/worlds.png" alt="ARM TrustZone worlds" id="armtrustzoneworlds" title="ARM TrustZone" style="height:219px;width:283px;" />
<figcaption>ARM TrustZone worlds</figcaption></figure>



<p>All Android and iOS phones currently use ARM processors.
ARM provides a dedicated security module, called <strong>TrustZone</strong>, that coexists with
the normal processor. The hardware is separated into
two &#8220;worlds&#8221;: <strong>secure</strong> (<strong>trusted</strong>) and <strong>non-secure</strong> (<strong>non-trusted</strong>) <strong>worlds</strong>.
Any software resides in only one of these two worlds and the processor
executes in only one world at a time.</p>

<p>Each of these <em>worlds</em> has
its own operating system and applications. Android systems run
an operating system called <a href="https://source.android.com/security/trusty">Trusty TEE</a> in the secure world and, of course, Linux in the untrusted world.</p>

<p>Logically, you can think of the two worlds as two distinct processors,
each running their own operating system with their own data and their own memory. Non-secure applications cannot access any own memory or registers of secure resources directly. The only way they can communicate is through a messaging API.</p>

<p>In practice, the hardware creates two <em>virtual cores</em> for each CPU core, managing separate registers
and all processing state in each world.</p>

<p>The phone&#8217;s operating system and all applications reside in the non-trusted
world. Secure components, such as cryptographic keys, signature services,
encryption services, and payment services live in the trusted world. Even the operating system
kernel does not have access to any of the code or data in the trusted world.
Hence, even if an app manages a privilege escalation attack and gains root
access, it will be unable to access certain security-critical data. </p>

<p>Applications for the trusted world include key management, secure boot,
digital rights management, secure payment processing, mobile payments, and biometric authentication.</p>

<h3 id="applesecureenclave">Apple Secure Enclave</h3>

<p>Apple uses modified ARM processors for iPhones and iPads. In 2013, they announced <strong>Secure Enclave</strong>
for their processors. The details are confidential but it appears to be similar in function to ARM&#8217;s
TrustZone but designed as a <em>physically separate</em> coprocessor.
As with TrustZone, the Secure Enclave coprocessor runs its own operating system
(a modified <a href="https://en.wikipedia.org/wiki/L4_microkernel_family">L4 microkernel</a> in this case).</p>

<p>The processor has its own secure bootloader and custom software update mechanism.
It uses encrypted memory so that anything outside the Secure Enclave cannot
access its data.
It provides:</p>

<ul>
<li>All cryptographic operations for data protection &amp; key management.</li>
<li>Random number generation.</li>
<li>Secure key store, including Touch ID (fingerprint) and the Face ID neural network.</li>
<li>Data storage for payment processing.</li>
</ul>

<p>The Secure Enclave maintains the confidentiality and integrity of data
even if the iOS kernel has been compromised.</p>


</div>

<div id="footer">
<hr/>
<style type="text/css">  
span.codedirection { unicode-bidi:bidi-override; direction: rtl; }  
</style>  

<p> &copy; 2003-2019 Paul Krzyzanowski. All rights reserved.</p>
<p>For questions or comments about this site, contact Paul Krzyzanowski, 
<span class="codedirection">gro.kp@ofnibew</span>
</p>
<p>
The entire contents of this site are protected by copyright under national and international law.
No part of this site may be copied, reproduced, stored in a retrieval system, or transmitted, in any form,
or by any means whether electronic, mechanical or otherwise without the prior written
consent of the copyright holder.
If there is something on this page that you want to use, please let me know.
</p>
<p>
Any opinions expressed on this page do not necessarily reflect the opinions of my employers and may not
even reflect my own.
</p>
<p> Last updated: May 20, 2020
</p>
<img class="stamp" src="../..//css/images/recycled_pixels_logo.png" alt="recycled pixels" height="80" width="80" />
</div> <!-- footer -->
<div id="tear">
</div>


<div id="sidebar1">
<h1 class="first">Contents </h1>
	<h2> CS 419 </h2>
	<ul>
	<li> <a href="../index.html"> Main course page </a> </li>
	<li> <a href="../news.html"> News </a> </li>
	<li> <a href="../syllabus.html"> Syllabus </a> </li>
	<li> <a href="../hw/index.html"> Homework </a> </li>
	<li> <a href="../notes/index.html"> Documents </a> </li>
	<li> <a href="../exam/index.html"> Exam info </a> </li>
	<li> <a href="../grades/index.html"> Check your grades </a> </li>
	<li> <a href="https://sakai.rutgers.edu/portal/site/a89b56d4-d72e-4e3d-865e-f7acfbce9964"> Sakai </a> </li>
	</ul>

	<h2> CS 419 background </h2>
	<ul>
	<li> <a href="../about.html"> About the course </a> </li>
	<li> <a href="../prereq.html"> Prerequisites </a> </li>
	<li> <a href="../things.html"> Things you need </a> </li>
	<li> <a href="../policy.html"> Policy  </a> </li>
	</ul>

		<h2> Study guides </h2>
	<ul>
	<li> <a href="../exam/guide-1.html"> Study Guide 1 </a> </li>
	<li> <a href="../exam/guide-2.html"> Study Guide 2 </a> </li>
	<li> <a href="../exam/guide-3.html"> Study Guide 3 </a> </li>
<!--
	<li> <a href="../exam/guide-final.html"> Full Study Guide </a> </li>
-->
	</ul>

</div>

<div id="sidebar2">
<!--
<h1 class="first"> Free junk </h1>
<p>
This is some stuff I'm throwing away. Please send me mail if you want any of it:
</p>
<hr/>
<ul>
<li> 
</ul>
-->
</div>

</div>
</div>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-8293152-1");
pageTracker._trackPageview();
} catch(err) {}</script>

</body>
</html>
